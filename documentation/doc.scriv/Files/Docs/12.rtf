{\rtf1\ansi\ansicpg1252\cocoartf1404\cocoasubrtf340
{\fonttbl\f0\fnil\fcharset0 OpenSans;\f1\fnil\fcharset0 Consolas;}
{\colortbl;\red255\green255\blue255;\red38\green38\blue38;\red245\green245\blue245;\red38\green38\blue38;
}
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\fi360\sl288\slmult1\pardirnatural\qj

\f0\fs28 \cf0 The starting point of the project was the paper provided by Dr. Jonathan E. Fieldsend [@fieldsend_2014] on the Niching Migratory Multi-Swarm Optimiser (NMMSO) algorithm. NMMSO is a multi-modal optimiser which relies heavily on multiple swarms that are generated on the landscape of a function in order to find the global optima. It is build around three main pillars: \
(1) dynamic in the numbers of dimensions, \
(2) self-adaptive without any special preparation and \
(3) exploitative local search to quickly find peak estimates [@fieldsend_2014, p. 1]. \
\
Multi-modal optimisation in general, does not differ very much from well known and widely discussed single-objective optimisation, but but unlike it, the goal of the algorithms in the multi-modal perspective is not to find just one single optimising point but all possible points [@fieldsend_2014, p. 1].  In order to do so, many early multi-modal optimisation algorithms needed defined parameters [@fieldsend_2014, p.1].\
\
**Maybe write a bit more about multi-modal algorithms in general**\
\
Newer algorithms fall in the field of self-tuning and try to use different mathematical paradigms like nearest-best clustering with covariance matrices [@preuss_2012] and strategies like storing the so far best found global optima estimators to provide them as parameters for new optimisation runs [@epitropakis_2013]. Contradictory to that NMMSO goes the way of many early algorithms and uses the swarm strategy in order to find which store their current [@fieldsend_2014]. \
\
In order to do so, NMMSO follow a strict structure, which can be seen in the following pseudo-code\
\
	nmmso (max_evals, tol, n, max_inc, c_1, c_2, omega)\
		S: initialise_swarm(1)\
		evaluations := 1\
		while evaluations < max_evals:\
			while flagged_swarms(S) == true:\
				\{S, m\} := attempt_merge(S, n, tol)\
				evals := evals + m\
			S := increment(S, n, max_inc, c_1, c_2, omega)\
			evals := evals + min(|S|, max_inc)\
			\{S, k\} := attempt_separation(S, tol)\
			evals := evals + k\
			S := add_new_swarm(S)\
			evals := evals + 1\
		\{X*, Y*\} := extract_gbest(S)\
		return X*,Y*\
\
This structure wasn't modified during the reimplementation of  NMMSO to keep comparability and the possibility to fix bugs at a high level. The only newly introduced setting was the possibility to modify c_1, c_2 and omega as parameters from the outside. In the original version those parameters are part of the program code. All other variables have been set to the variables seen in the following table. While variables like maximal amount of evaluations are dependent on the used test function and have been explicitly stated in the test function by the CEC (Section 3.1) other values have been chosen by Dr. Fieldsend and were used for the reimplementation [@fieldsend_2014, p. 2-3]. Those values can be found in the following table:\
\
           		used value 	\
-----------	 	--------------\
evaluations		0			\
max_inc			100			\
tol				10^-6		\
c_1				2.0         \
c_2				2.0	        \
omega			0.1       	\
---------  		--------------   \
\pard\pardeftab720\sl380

\f1 \cf2 \cb3 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 Table: Values used for all program evaluations.   \
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\fi360\sl288\slmult1\pardirnatural\qj

\f0 \cf4 \cb1 \outl0\strokewidth0 \
}