{\rtf1\ansi\ansicpg1252\cocoartf1404\cocoasubrtf340
{\fonttbl\f0\fnil\fcharset0 OpenSans;}
{\colortbl;\red255\green255\blue255;\red38\green38\blue38;\red255\green255\blue255;}
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\fi360\sl288\slmult1\pardirnatural\qj

\f0\fs28 \cf0 The starting point of the project was the paper provided by Dr. Jonathen E. Fieldsend [@fieldsend_2014] on the Niching Migratory Multi-Swarm Optimiser (NMMSO) algorithm. NMMSO is a multi-modal optimiser which relies heavily on multiple swarms which are generated on the landscape of an function in order to find the global optimum. It is build around three main pillars: (1) dynamic in the numbers of dimensions, (2) self-adaptive without any special preparation and (3) exploitative local search to quickly find peak estimates [@fieldsend_2014, p. 1]. \
\
Multi-modal optimisation in general is not that different from well known and widely discussed single-objective optimisation, but in difference to it the goal of the algorithms in the multi-modal is not to find just one single optimising point but all possible points [@fieldsend_2014, p. 1]. In order to do so, many early multi-modal optimisation algorithms needed defined parameters [TODO: quote needed]. \
\

\b **maybe it would be interesting to write a few more lines about the history of evolutionary algorithms here?**
\b0 \
\
Newer algorithms fall in the field of self-tuning and try to use different mathematical paradigms like nearest-best clustering with covariance matrices [@preuss_2012] and strategies like storing the so far best found global optima estimators to provide them as parameters for new optimisation runs [@epitropakis_2013]. Contradictory to that NMMSO goes another way and uses the the swarm strategy in order to find which store their current [@fieldsend_2014]\
\
In order to do so NMMSO follow a strict structure which can be seen in the following pseudo-code\
\
	nmmso(max_evals, tol, n, max_inc, c_1, c_2, chi, w)\
		S: initialise_swarm(1)\
		evaluations := 1\
		while evaluations < max_evals:\
			while flagged_swarms(S) == true:\
				\{S, m\} := attempt_merge(S, n, tol)\
				evals := evals + m\
			S := increment(S, n, max_inc, c_1, c_2, chi, w)\
			evals := evals + min(|S|, max_inc)\
			\{S, k\} := attempt_separation(S, tol)\
			evals := evals + k\
			S := add_new_swarm(S)\
			evals := evals + 1\
		\{X*, Y*\} := extract_gebsest(S)\
		return X*,Y*\
\
This structure wasn't modified during the reimplementation of  NMMSO to keep comparability and the possibility to fix bugs at a high level. The only newly introduced setting was the possibility to modify the c_1, c_2, chi, w as parameters from the outside. In the original version those parameters are part of the program code.\
\
    .      standard value 	used value     \
--------   --------------	----------\
evaluations	0				0\
max_evol	100				100\
tol_val		10^-6			10^-6\
c_1			2.0             2.0\
c_2			2.0	            2.0\
omega		0.1       		0.1\
---------  --------------   ----------\cf2 \cb3 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 \
\cf0 \cb1 \kerning1\expnd0\expndtw0 \outl0\strokewidth0 \

\b **What else about the algorithm need to be explained that isn't explicitly part of the implementation?**}