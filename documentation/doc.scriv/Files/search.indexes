<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<SearchIndexes Version="1.0">
    <Documents>
        <Document ID="19">
            <Title>Conclusion</Title>
            <Text>test</Text>
        </Document>
        <Document ID="15">
            <Title>Pitfalls and Problems</Title>
            <Text>test</Text>
        </Document>
        <Document ID="21">
            <Title>cec2013-niching-benchmark-tech-report</Title>
            <Text>Benchmark Functions for CEC’2013 SpecialSession and Competition on Niching Methods forMultimodal Function Optimization Xiaodong Li, Andries Engelbrecht, Michael G. EpitropakisEvolutionary Algorithms (EAs) in their original forms are usually designed for locating a single global solution. These algorithms typically converge to a single solution because of the global selection scheme used. Nevertheless, many real- world problems are “multimodal” by nature, i.e., multiple satisfactory solutions exist. It may be desirable to locate many such satisfactory solutions so that a decision maker can choose one that is most proper in his/her problem domain. Numerous techniques have been developed in the past for locating multiple optima (global or local). These techniques are commonly referred to as “niching” methods. A niching method can be incorporated into a standard EA to promote and maintain formation of multiple stable subpopulations within a single population, with an aim to locate multiple globally optimal or suboptimal solutions. Many niching methods have been developed in the past, including crowding [1], fitness sharing [2], deterministic crowding [3], derating [4], restricted tournament selection [5], parallelization [6], stretching and deflation [7], clustering [8], clearing [9], and speciation [10], etc.Although these niching methods have been around for many years, further advances in this area have been hindered by several obstacles: most studies focus on very low dimen- sional multimodal problems (2 or 3 dimensions), therefore it is difficult to assess these methods’ scalability to high dimensions; some niching methods introduces new parameters which are difficult to set, making these methods difficult to use; different benchmark test functions or different variants of the same functions are used, hence comparing the performance of different niching methods is difficult.We believe it is now time to adopt a unifying framework for evaluating niching methods, so that further advance in this area can be made with ease. In this technical report, we put together 20 benchmark test functions (including several identical functions with different dimension sizes), with dif- ferent characteristics, for evaluating niching algorithms. The first 10 benchmark functions are simple, well known and widely used functions, largely based on some recent studies on niching [11], [12], [13]. The remaining benchmark functionsXiaodong Li is with the School of Computer Science and IT, RMIT University, VIC 3001, Melbourne, Australia, email: xiaodong.li@rmit.edu.au Andries Engelbrecht is with the Department of Computer Science, School of Information Technology, University of Pretoria, Pretoria 0002, South Africa,email: engel@cs.up.ac.zaMichael G. Epitropakis is with the Department of Computing Science andMathematics, School of Natural Sciences, University of Stirling, Stirling FK9 4LA, Scotland, email: mge@cs.stir.ac.ukare more complex and follow the paradigm of composition functions defined in the IEEE CEC 2005 special session on real-parameter optimization [14].Several of the test functions included here are scalable to dimension, and the number of global optima can be adjusted freely by the user. Performance measures are also defined and suggested here for comparing different niching methods. The source codes of the benchmark test functions are made avail- able in Matlab, Java and C++ source codes. The competition files can be downloaded from the CEC’2013 special session on niching methods website1 .In the following sections, we will describe the mathematical formula and properties of the included multimodal benchmark test functions, evaluation criteria, and the ranking method for entries submitted to this competition.I. SUMMARY OF TEST FUNCTIONSThis benchmark set includes the following 20 multimodal test functions:• F1 :• F2 :• F3 :• F4 :• F5 :• F6 :• F7: Vincent (2D, 3D)• F8: Modified Rastrigin - All Global Optima (2D)• F9 : Composition Function 1 (2D)Five-Uneven-Peak Trap (1D) Equal Maxima (1D)Uneven Decreasing Maxima (1D) Himmelblau (2D)Six-Hump Camel Back (2D) Shubert (2D, 3D)• F10 : Composition Function 2 (2D)• F11: Composition Function 3 (2D, 3D, 5D, 10D)• F12: Composition Function 4 (3D, 5D, 10D, 20D) These multimodal test functions have following properties:• All test functions are formulated as maximization prob-lems;• F1, F2 and F3 are simple 1D multimodal functions;• F4 and F5 are simple 2D multimodal functions. Thesefunctions are not scalable;• F6 to F8 are scalable multimodal functions. The numberof global optima for F6 and F7 are determined by the dimension D. However, for F8, the number of global op- tima is independent from D, therefore can be controlled by the user.• F9 to F12 are scalable multimodal functions constructed by several basic functions with different properties. F91URL: http://goanna.cs.rmit.edu.au/∼xiaodong/cec13-niching/1
2￼￼￼￼￼￼￼￼￼￼￼￼￼and F10 are separable, and non-symmetric, while F11 and F12 are non-separable, non-symmetric complex mul- timodal functions. The number of global optima in all composition functions is independent from D, therefore can be controlled by the user.II. DEFINITIONS OF THE TEST FUNCTIONS10.90.80.70.60.50.40.30.20.100 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1Equal Maxima.￼￼￼￼￼￼￼￼￼￼￼￼A. F1: Five-Uneven-Peak Trap80(2.5 − x) 64(x − 2.5) 64(7.5 − x)28(x − 7.5)28(17.5 − x) 32(x − 17.5) 32(27.5 − x)80(x − 27.5)for0≤x&lt;2.5, for2.5≤x&lt;5.0, for5.0≤x&lt;7.5, for7.5≤x&lt;12.5, for12.5≤x&lt;17.5, for17.5≤x&lt;22.5, for22.5≤x&lt;27.5, for27.5≤x≤30.Fig. 2.￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼F1(x) =Properties:Properties:– Variable ranges: x ∈ [0, 1]; – No. of global optima: 1;– No. of local optima: 4;This function was originally proposed in [15]. See Fig. 3.10.90.80.70.60.50.40.30.20.100 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1Fig. 3. Uneven Decreasing Maxima.D. F4 : HimmelblauF4(x,y)=200−(x2 +y−11)2 −(x+y2 −7)2.Properties:– Variableranges:x,y∈[−6,6]; – No. of global optima: 4;– No. of local optima: 0;This is an inverted version of Himmelblau function [15]. It has 4 global optima with 2 closer to each other than the other 2. There are no local optima, as shown in Fig. 4.E. F5: Six-Hump Camel BackF5(x,y)=−4[(4−2.1x2 + 3 )x2 +xy+(4y2 −4)y2].– Variable ranges: x ∈ [0, 30]; – No. of global optima: 2;– No. of local optima:3.￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼This function was originally proposed in [10]. See Fig. 1.2001801601401201008060402000 5 10 15 20 25 30Five-Uneven-Peak Trap.￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼Fig. 1.B. F2: Equal Maxima F2(x) = sin6(5πx).Properties:– Variable ranges: x ∈ [0, 1]; – No. of global optima: 5;– No. of local optima: 0;This function was originally proposed in [15]. See Fig. 2.C. F3: Uneven Decreasing Maxima   x−0.08 2 0.854x4F (x) = exp −2log(2) 3sin6(5π(x3/4−0.05)).￼￼
￼￼where there are 18 global optima in 9 pairs (each with an objective function value of 186.73), with each pair very close to each other, but the distance between any pair is much greater. There are in total 760 global and local optima.3￼￼￼￼￼￼￼￼￼￼￼￼Fig. 4.Himmelblau.￼Properties:– Variable ranges: x ∈ [−1.9, 1.9]; y ∈ [−1.1, 1.1];– No. of global optima: 2;– No. of local optima: 2;This function was originally proposed in [16]. The function has 2 global optima as well as 2 local optima. See Fig. 5.Fig. 6.Shubert 2D function.sin(10log(xi))￼G. F7: Vincent F7(⃗x) = 1  D￼￼D i=1 Properties:￼– Variable range: xi ∈ [0.25,10]D,i = 1,2,...,D – No. of global optima: 6D;– No. of local optima: 0;This is an inverted version of the Vincent function [17], which has 6D global optima (each with an objective function value of 1.0), but unlike the regular distances between global optima in F6, in Vincent function the global optima have vastly different spacing between them. In addition, the Vincent function has no local optima. Fig. 7 shows an example of the Vincent 2D function.￼￼￼￼￼￼Fig. 5.Six-Hump Camel Back.￼F. F6: ShubertF6(⃗x) = −  Di=1  5j=1 jcos[(j + 1)xi + j]. Properties:– Variable ranges: xi ∈ [−10,10]D,i = 1,2,...,D; – No.ofglobaloptima:D·3D;– No. of local optima: many;This function is an inverted version of the Shubert function [16], [10], where there are n3D global optima unevenly distributed. These global optima are divided into 3D groups, with each group having D global optima being close to each other. Fig. 6 shows an example of the Shubert 2D function,Fig. 7.Vincent 2D function.￼￼￼
H. F : Modified Rastrigin - All Global Optima weight, o⃗ is the new shifted optimum of each fˆ , M is the 8iii D(10 + 9cos(2πkixi)).i=1– Variable ranges: xi ∈ [0,1]D,i = 1,2,...,D; – No. of global optima:  Di=1 ki;– No. of local optima: 0;a parameter which is used to stretch (λi &gt; 1) or compress (λ &lt; 1) each fˆ function. The composition function includesF9(⃗x) = − Properties:iitwo bias parameters biasi and fj . The former defines aThis is a modified Rastrigin function according to [13]. The total number of global optima is M =  D k . In [13], aoptimum is the global optimum, while the latter defines afunction value bias for the constructed composition function.Here, we set the biasi = 0,∀i ∈ {1,2,...,n}, thus the globaloptimum of each basic function is a global optimum of thecomposition function. In addition, we set fj = 0, as such biasin each composition function, all global optima have fitness values equal to zero.The weight wi of each basic function can be easily calcu- lated based on the following equations:i=1 iproblem instance D = 16 was used, with the following setting:ki = 1, for i = 1−3,5−7,9−11,13−15, and k4 = 2,k8 = 2,k12 = 3,k16 = 4. In this case, there are 48 evenly distributed global optima, each having an identical objective value of f = 16. Fig. 8 provides a problem instance of this function in 2D (where D = 2,k1 = 3,k2 = 4), in which case the total number of optima is 12.   Dk=1(xk − oik)2   wi=exp − 2Dσ2 , linear transformation (rotation) matrix of each fˆ, and λ is iibiasfunction value bias for each basic function and denotes which4￼wi =wiwi(1 − max(wi)10) otherwise.iwi = max(wi)￼￼Finally, the weights are normalized according to wi = wi/  ni=1 wi. The parameter σi controls the coverage range of each basic function, with small values to produce a narrow coverage range to the corresponding fˆ .The pool of basic functions may include functions withdifferent properties, characteristics and heights. As such tohave a better mixture of the basic functions a normalizationprocedure is incorporated. The normalized function fˆ , can be idefined as: fˆ(·) = Cf (·)/|fi |, where C is a predefined i i maxconstant (C = 2000) and fmiax is estimated using: fmiax = fi ((x⋆/λi)Mi), with x⋆ = [5,5,...,5].The pool of basic functions that we have used to construct the composition functions includes the following:￼i￼￼￼￼Fig. 8.Modified Rastrigin - All Global Optima 2D function.Df S ( ⃗x ) =   x 2i .i=1I. Composition functionsIn this section, we first describe the general framework for constructing multimodal composition functions with several global optima, then present the new composition functions used in this technical report.More specifically, a D-dimensional, composition function CFj : AD ⊂ RD → R can be generally constructed as a weighted aggregation of n basic functions fi : AD ⊂ RD → R. Each basic function is shifted to a new position inside the optimization space AD and can be either rotated through a linear transformation matrix or used as is. Thus, a composition function CFj is calculated according the following equation:n CF(⃗x)= w fˆ((⃗x−o⃗)/λ·M)+bias +fj ,Grienwank’s function:––––Sphere function:fG(⃗x) =i=1Rastrigin’s function:4000 − cos √i i=1+ 1. D x2i  D  xi ￼￼￼j iiiiiibiasi=1  k k where n is the number of basic functions used to construct −Dα cos 2πβ (0.5) , i-th basic function, i ∈ {1, 2, . . . , n}, wi is the corresponding where α = 0.5, β = 3, and kmax = 20.the composition function, fˆ denotes a normalization of the ik=0DfR(⃗x)=  x2i −10cos(2πxi)+10 .i=1 Weierstrass function:D  kmax   fW(⃗x)=   αk cos 2πβk(xi +0.5) i=1 k=0 kmax
5￼– Expanded Griewank’s plus Rosenbrock’s function (EF8F2):￼ D x2i  D  xi  F8(⃗x)= 4000 − cos √ii=1 i=1 D−1+1,￼￼￼￼F2(⃗x)=   100(x2i −xi+1)2 +(xi −1)2 , i=1EF8F2(⃗x)=F8F2(x1,x2,...,xD) =F8(F2(x1,x2))+F8(F2(x2,x3))+...+F8(F2(xD−1,xD))+F8(F2(xD,x1))It is clear that the aforementioned basic functions do not incorporate either shifted positions, or linear transfor- mations (rotations). Thus, in order to calculate for example fS ((⃗x − o⃗i)/λi · Mi) , one can easily first calculate ⃗z = (⃗x − o⃗i)/λi · Mi and subsequently fS(⃗z). It has to be noted that all composition functions are formulated as maximization problems.Note on the implementation: The implementation of the composition functions has been mostly based on the source code of the IEEE CEC 2005 competition on real-parameter optimization [14]. However, the source code has been re- implemented from scratch in a simplified and scalable way. It has to be noted that, similar implementation of composition functions with multiple global optima was proposed in [18]. However, our implementation of the composition functions are different in many ways: new structures, parameters, rotation matrices, and shifted optima positions.J. F9 : Composition Function 1Composition Function 1 (CF1) is constructed based on six basic functions (n = 6), thus it has six global optima in the optimization box AD = [−5, 5]D . The basic functions used here include the following:– f1 − f2 : Grienwank’s function,– f3 − f4 : Weierstrass function, and – f5 − f6 : Sphere function.The composition function is constructed based on the follow- ing parameter settings:– σi = 1,∀i ∈ {1,2,...,n},– ⃗λ = [1,1,8,8,1/5,1/5],– Mi are identity matrices ∀i ∈ {1,2,...,n}.Fig. 9 shows the 2D version of CF1. Properties:– Multi-modal,– Shifted,– Non-Rotated,– Non-symmetric,– Separable near the global optima,– Scalable,Fig. 9.Composition Function 1.￼￼￼￼K. F10 : Composition Function 2Composition Function 2 (CF2) is constructed based on eight basic functions (n = 8), thus it has eight global optima in theoptimization here include– f1 − f2 – f3 − f4 – f5 − f6 – f7 − f8box AD = [−5, 5]D . The basic functions used the following:: Rastrigin’s function,: Weierstrass function,: Griewank’s function, and : Sphere function.The composition function is constructed based on the follow- ing parameter settings:– σi = 1,∀i ∈ {1,2,...,n},– ⃗λ=[1,1,10,10,1/10,1/10,1/7,1/7],– Mi are identity matrices ∀i ∈ {1,2,...,n}.Fig. 10 shows the 2D version of CF2.￼￼￼￼￼￼￼– Numerous local optima,– Different function’s properties are mixed together,– Sphere Functions give two flat areas for the function,– In the optimization box AD = [−5, 5]D , there areFig. 10.Composition Function 2.six global optima x⃗⋆i = o⃗i,i ∈ {1,2,...,n} with CF1(x⃗⋆i ) =Properties:– Multi-modal, – Shifted,0,∀i ∈ {1,2,...,n}.
– Non-Rotated,– Non-symmetric,– Separable near the global optima,– Scalable,– Numerous local optima,– Different function’s properties are mixed together,– In the optimization box AD = [−5,5]D, there are eightglobal optima x⃗⋆i = o⃗i,i ∈ {1,2,...,n} with CF2(x⃗⋆i ) = 0,∀i ∈ {1,2,...,n}.L. F11 : Composition Function 3Composition Function 3 (CF3) is constructed based on six basic functions (n = 6), thus it has six global optima in the optimization box AD = [−5, 5]D . The basic functions used here include the following:– f1 − f2 : EF8F2 function,– f3 − f4 : Weierstrass function, and – f5 − f6 : Griewank’s function.The composition function is constructed based on the follow- ing parameter settings:– ⃗σ = [1,1,2,2,2,2],– ⃗λ = [1/4,1/10,2,1,2,5],– Mi are different linear transformation (rotation) matriceswith condition number one.Fig. 11 shows the 2D version of the CF3.M. F12 : Composition Function 4Composition Function 4 (CF4) is constructed based on eight basic functions (n = 8), thus it has eight global optima in the optimization box AD = [−5, 5]D . The basic functions used here include the following:– f1 − f2 : Rastrigin’s function,– f3 − f4 : EF8F2 function,– f5 − f6 : Weierstrass function, and – f7 − f8 : Griewank’s function.The composition function is constructed based on the follow- ing parameter settings:– ⃗σ = [1,1,1,1,1,2,2,2],– ⃗λ = [4, 1, 4, 1, 1/10, 1/5, 1/10, 1/40],– Mi are different linear transformation (rotation) matriceswith condition number one.Fig. 12 shows the 2D version of the CF4.6￼￼￼￼￼￼￼￼￼￼￼￼￼Fig. 11.Composition Function 3.Properties:– Multi-modal,– Shifted,– Rotated,– Non-symmetric,– Non-separable,– Scalable,– A huge number of local optima,– Different function’s properties are mixed together,– In the optimization box AD = [−5,5]D, there are eightglobal optima x⃗⋆i = o⃗i,i ∈ {1,2,...,n} with CF4(x⃗⋆i ) = 0,∀i ∈ {1,2,...,n}.III. PERFORMANCE MEASURESA. How to determine if all global optima are found?Our objective is to compare different niching algorithms’ capability to locate all global optima. To achieve this, first we need to specify a level of accuracy (typically 0 &lt; ε ≤ 1), a threshold value under which we would consider a global optimum is found. Second, we assume that for each test function, the following information is available:Properties:– Multi-modal,– Shifted,– Rotated,– Non-symmetric,– Non-separable,– Scalable,– A huge number of local optima,– Different function’s properties are mixed together,– In the optimization box AD = [−5, 5]D , there aresix global optima x⃗⋆i = o⃗i,i ∈ {1,2,...,n} with CF3(x⃗⋆i ) =0,∀i ∈ {1,2,...,n}.Fig. 12.Composition Function 4.￼
• The number of global optima;• The fitness of the global optima (or peak height), whichis known or can be estimated;• A niche radius value that can sufficiently distinguish twoclosest global optima.This information is required by Algorithm 1 (based on apreviously proposed procedure [19]), to determine if a niching algorithm has located all the global optima (Table IV provides an example of how this information is used for performance measures in this competition). Basically, at the end of an optimization run, Algorithm 1 is invoked to check all the individuals on the sorted list Lsorted, starting from the best- fit individual. In the first iteration, as long as this best-fit individual is within ε distance from the fitness of the global optima ph, it will be added to the solution list S (which is initially empty). In the next iteration, the next best-fit individual from Lsorted is first assigned to p. We then check if the fitness of p is close enough to that of the global optima (i.e., if d(ph, f it(p)) ≤ ε). If p is close enough (in other words, p is a potential solution), then next we check if p is within the niche radius r from all the current solutions in the solution list S. If it is not, then p is considered as a new solution (i.e., a new global optimum is found), and will be added to S. Otherwise p is not considered as a distinct solution, and will be skipped. This process is repeated until all the individuals on Lsorted have been checked. It is important to note that Algorithm 1 is only used for performance measurement in determining if a sufficient number of global optima has been found, but not in any part of the optimization procedure.The output of Algorithm 1 is S, a solution list containing all the distinct global optima found. As long as r is set to a value not greater than the distance between 2 closest global optima, individuals on two found global optima would be treated as two different solutions. Since the exact number of global optima is known a priori, we can measure a niching algorithm’s performance in terms of the peak ratio, success rate, and averaged number of evaluations required to achieve a given accuracy ε for locating all global optima over multiple runs. These will be described in the following sections.B. Peak ratio and success rateWe use peak ratio (PR) [20] and success rate (SR) as two performance measures, to evaluate the performance of a niching algorithm over multiple runs. Given a fixed maximum number of function evaluations (MaxFEs) and a required accuracy level ε, PR measures the average percentage of all known global optima found over multiple runs:Algorithm 1: The algorithm for determining if all global optima are found.where NSR denotes the number of successful runs. C. Convergence speedWe measure the convergence speed of a niching algorithm by counting the number of function evaluations (FEs) required to locate all known global optima, at a specified accuracy level ε. We calculate the average FEs over multiple runs:AveFEs = NR FEirun=1 , (3)NR7￼￼￼input : Lsorted - a list of individuals (candidate solu- tions) sorted in decreasing fitness values;ε - accuracy level; r - niche radius;ph - the fitness of global optima (or peak height)output: S - a list of best-fit individuals identified as solutionsbeginS = ∅;while not reaching the end of Lsorted doGet best unprocessed p ∈ Lsorted; found ← FALSE;if d(ph, f it(p)) ≤ ε) thenfor all s ∈ S doif d(s, p) ≤ r thenfound ← TRUE;break;end endif not found then let S ← S ∪ {p};end endend end￼￼￼￼￼￼￼￼PR = NR NPFirun=1 , (1)where F Ei denotes the number of evaluations used in the i-th run. If the algorithm cannot locate all the global optima by the MaxFEs, then MaxFEs is used when calculating the average FEs.IV. EXPERIMENTAL SETTINGSWe evaluate niching methods by using a fixed amount of MaxFEs. A user is allowed to use any population size, but only a fixed amount of MaxFEs is allowed to be used as a given computational budget.A. Peak ratio and success ratePR and SR are calculated according to equations (1) and (2). The following parameter settings are used:• Level of accuracy (ε): {1.0E-01,1.0E-02, . . . , 1.0E-05};• Niche radius (r): See Table IV;￼NKP ∗NRwhere N P Fi denotes the number of global optima found in theend of the i-th run, NKP the number of known global optima, and NR the number of runs. SR measures the percentage of successful runs (a successful run is defined as a run where all known global optima are found) out of all runs:SR = NSR, (2) NR￼
• Initialization: Uniform random initialization within the search space;• Termination of a run: Terminate when reaching MaxFEs.• Number of runs: 50.Note that ε and r are to be used only at the end of a run, for evaluations of the final solutions. Table I shows different MaxFEs used for the 3 ranges of test functions.TABLE IMAXFES USED FOR 3 RANGES OF TEST FUNCTIONS.TABLE IVPARAMETERS USED FOR PERFORMANCE MEASUREMENT.8￼￼￼r￼Peak height￼￼0.01￼200.0￼￼0.01￼1.0￼￼0.01￼1.0￼￼0.01￼200.0￼￼0.5￼1.03163￼￼0.5￼186.731￼￼0.2￼1.0￼￼0.5￼2709.0935￼￼0.2￼1.0￼￼0.01￼-2.0￼￼0.01￼0￼￼0.01￼0￼￼0.01￼0￼￼0.01￼0￼￼0.01￼0￼￼0.01￼0￼￼0.01￼0￼￼0.01￼0￼￼0.01￼0￼￼0.01￼0￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼Range of functionsF1 to F5 (1D or 2D) F6 to F11 (2D)MaxFEs 5.0E+04 2.0E+05FunctionF1 (1D) F2 (1D) F3 (1D) F4 (2D) F5 (2D) F6 (2D) F7 (2D) F6 (3D) F7 (3D) F8 (2D) F9 (2D) F10 (2D) F11 (2D) F11 (3D) F12 (3D) F11 (5D) F12 (5D) F11 (10D) F12 (10D) F12 (20D)No. global optima 25142183681216126866868688￼￼￼￼￼￼￼￼F6 to F12 (3D or higher) ￼ 4.0E+05ForF8 (2D),wesetk1 =3andk2 =4,asshownin Fig. 8. Table II shows an example of presenting PR and SR values of a typical niching algorithm. Note that in this example the PR and SR values are calculated based on the results of a baseline model, DE/nrand/1/bin algorithm (see details in a section below).B. Convergence speedConvergence speed is calculated according to equation (3), using the same MaxFEs settings in Table I. The accuracy level ε is set to 1.0E-04. Other parameters are the same as in Table IV. Table V presents the convergence speed results of the DE/nrand/1/bin algorithm.To further illustrate the behaviour of the niching algorithm, we can record the number of global optima found at different iteration steps of a run. We recommend to use figures to show the mean global optima found averaged over 50 runs, on 5 or 6 different test functions of your choice. We encourage authors to follow a recent paper on niching [21] on how to better present results.C. Baseline modelsTo facilitate easy comparisons for participants in the competition, we use as baseline models two Differen- tial Evolution (DE) niching variants, the recently proposed DE/nrand/1/bin algorithm [21] and the well known Crowding DE/rand/1/bin [20]. DE/nrand/1/bin is a simple DE algorithm which incorporates spatial information about the neighborhood of each potential solution to produce a niching formation. On the other hand, Crowding DE/rand/1/bin produces niching formation by incorporating the crowding technique to maintain a better population diversity and therefore to prevent premature convergence to an optimum. The results of the two baseline models are presented in Tables II, III, and Tables V, VI. Please note that we did not conduct any fine-tuning on the parameters of the baseline algorithms. Instead, we used the following default parameters: population size NP = 100, F = 0.5, CR = 0.9, and the crowding factor equals to the population size CF = NP.TABLE VCONVERGENCE SPEEDS OF THE DE/NRAND/1/BIN ALGORITHM (WITH ACCURACY LEVEL ε = 1.0E-04).￼￼￼￼￼￼￼￼￼￼￼￼￼F1 (1D)F2 (1D)￼￼F3 (1D)￼F4 (2D)￼￼22886.0 2689.056￼￼1552.0 386.106￼￼1258.0 781.179￼￼￼13610.0 1399.453￼￼￼F6 (2D)F7 (2D)￼￼F6 (3D)￼F7 (3D)￼￼200000.0 0.000200000.0 0.000￼￼400000.0 0.000￼400000.0 0.000￼￼F9 (2D)F10 (2D)￼￼F11 (2D)￼F11 (3D)￼￼200000.0 0.000￼￼181658.0 42543.630￼￼200000.0 0.000￼￼￼400000.0 0.000￼F11 (5D)F12 (5D)F11 (10D)F12 (10D)￼￼400000.0 0.000￼￼400000.0 0.000￼￼400000.0 0.000￼￼￼400000.0 0.000￼￼FunctionMeanSt. D.FunctionF5 (2D) 3806.0 618.890 F8 (2D) 9858.0￼￼￼MeanSt. D. ￼ ￼ ￼ ￼ ￼ 833.015￼FunctionMeanSt. D.Function ￼ ￼ ￼ ￼ ￼ F12 (20D)F12 (3D) 400000.0 0.000￼￼￼Mean St. D.400000.0 0.000￼￼TABLE VICONVERGENCE SPEEDS OF THE CROWDING DE/RAND/1/BIN ALGORITHM (WITH ACCURACY LEVEL ε = 1.0E-04).￼￼￼F1 (1D)￼F2 (1D)￼F3 (1D)￼F4 (2D)￼￼50000.0 0.000￼￼￼3386.0 1368.749￼￼2576.0 2625.974￼￼41666.0 3772.598￼￼￼F6 (2D)￼F7 (2D)￼F6 (3D)￼F7 (3D)￼￼200000.0 0.000￼￼￼200000.0 0.000￼￼400000.0 0.000￼￼400000.0 0.000￼￼￼F9 (2D)￼F10 (2D)￼F11 (2D)￼F11 (3D)￼￼200000.0 0.000￼￼￼200000.0 0.000￼￼200000.0 0.000￼￼400000.0 0.000￼F11 (5D)F12 (5D)F11 (10D)F12 (10D)￼￼400000.0 0.000￼￼￼400000.0 0.000￼￼400000.0 0.000￼￼400000.0 0.000￼￼FunctionMeanSt. D.FunctionMeanSt. D.FunctionMeanF5 (2D)12980.0 2046.799 F8 (2D) 30306.0 1984.677 F12 (3D) 400000.0 0.000￼￼￼￼￼St. D.Function ￼ ￼ ￼ ￼ ￼ F12(20D)￼￼Mean St. D.400000.0 0.000￼￼V. RANKING METHODWe will use peak ratio values in Table II as our key criterion to rank algorithms submitted to this competition. The top algorithm is the one that obtains the best average peak ratio, across all test functions and 5 accuracy levels. If there is a tie, then the algorithm having the lower AveFEs in Table V will be the winner.
REFERENCES[1] K.A.DeJong,“Ananalysisofthebehaviorofaclassofgeneticadaptive systems.” Ph.D. dissertation, University of Michigan, 1975.[2] D. E. Goldberg and J. Richardson, “Genetic algorithms with sharing for multimodal function optimization,” in Proc. of the Second International Conference on Genetic Algorithms, J. Grefenstette, Ed., 1987, pp. 41–49.[3] S. W. Mahfoud, “Crowding and preselection revisited,” in Parallel problem solving from nature 2, R. Ma ̈nner and B. Manderick, Eds. Amsterdam: North-Holland, 1992, pp. 27–36. [Online]. Available: citeseer.ist.psu.edu/mahfoud92crowding.html[4] D. Beasley, D. R. Bull, and R. R. Martin, “A sequential niche technique for multimodal function optimization,” Evolutionary Computation, vol. 1, no. 2, pp. 101–125, 1993. [Online]. Available: citeseer.ist.psu. edu/beasley93sequential.html[5] G. R. Harik, “Finding multimodal solutions using restricted tournament selection,” in Proc. of the Sixth International Conference on Genetic Algorithms, L. Eshelman, Ed. San Francisco, CA: Morgan Kaufmann, 1995, pp. 24–31. [Online]. Available: citeseer.ist.psu.edu/harik95finding. html[6] M. Bessaou, A. Pe ́trowski, and P. Siarry, “Island model cooperating with speciation for multimodal optimization,” in Parallel Problem Solving from Nature - PPSN VI 6th International Conference, H.-P. S. et al., Ed. Paris, France: Springer Verlag, 16-20 2000. [Online]. Available: citeseer.ist.psu.edu/bessaou00island.html[7] K.E.ParsopoulosandM.N.Vrahatis,“Onthecomputationofallglobal minimizers through particle swarm optimization,” IEEE Transactions on Evolutionary Computation, vol. 8, no. 3, pp. 211–224, 2004.[8] X. Yin and N. Germay, “A fast genetic algorithm with sharing scheme using cluster analysis methods in multi-modal function optimization,” in the International Conference on Artificial Neural Networks and Genetic Algorithms, 1993, pp. 450–457.[9] A. Pe ́trowski, “A clearing procedure as a niching method for genetic algorithms,” in Proc. of the 3rd IEEE International Conference on Evolutionary Computation, 1996, pp. 798–803.[10] J.-P. Li, M. E. Balazs, G. T. Parks, and P. J. Clarkson, “A species conserving genetic algorithm for multimodal function optimization,” Evol. Comput., vol. 10, no. 3, pp. 207–234, 2002.[11] X.Li,“Nichingwithoutnichingparameters:Particleswarmoptimization using a ring topology,” IEEE Trans. on Evol. Comput., vol. 14, no. 1, pp. 150 – 169, February 2010.[12] K. Deb and A. Saha, “Finding multiple solutions for multimodal optimization problems using a multi-objective evolutionary approach,” in Proceedings of the 12th annual conference on Genetic and evolutionary computation, ser. GECCO ’10. New York, NY, USA: ACM, 2010, pp. 447–454.[13] A. Saha and K. Deb, “A bi-criterion approach to multimodal optimiza- tion: self-adaptive approach,” in Proceedings of the 8th international conference on Simulated evolution and learning, ser. SEAL’10. Berlin, Heidelberg: Springer-Verlag, 2010, pp. 95–104.[14] P. N. Suganthan, N. Hansen, J. J. Liang, K. Deb, Y. P. Chen, A. Auger, and S. Tiwari, “Problem definitions and evaluation criteria for the CEC 2005 special session on real-parameter optimization,” Nanyang Technological University and KanGAL Report #2005005, IIT Kanpur, India., Tech. Rep., 2005.[15] K. Deb, “Genetic algorithms in multimodal function optimization (mas- ter thesis and tcga report no. 89002),” Ph.D. dissertation, Tuscaloosa: University of Alabama, The Clearinghouse for Genetic Algorithms, 1989.[16] Z. Michalewicz, Genetic Algorithms + Data Structures = Evolution Programs. New York: Springer-Verlag, New York, 1996.[17] O. Shir and T. Ba ̈ck, “Niche radius adaptation in the cms-es niching algorithm,” in Parallel Problem Solving from Nature - PPSN IX, 9th International Conference (LNCS 4193). Reykjavik, Iceland: Springer, 2006, pp. 142 – 151.[18] B.-Y. Qu and P. N. Suganthan, “Novel multimodal problems and differential evolution with ensemble of restricted tournament selection,” in Proceedings of the IEEE Congress on Evolutionary Computation, CEC 2010. Barcelona, Spain: IEEE, 18-23 July 2010, pp. 1–7.[19] D.ParrottandX.Li,“Locatingandtrackingmultipledynamicoptimaby a particle swarm model using speciation,” IEEE Trans. on Evol. Comput., vol. 10, no. 4, pp. 440–458, August 2006.[20] R. Thomsen, “Multimodal optimization using crowding-based differen- tial evolution,” in Proceedings of the 2004 IEEE Congress on Evolu- tionary Computation. Portland, Oregon: IEEE Press, 20-23 Jun. 2004, pp. 1382–1389.[21] M. Epitropakis, V. Plagianakos, and M. Vrahatis, “Finding multiple global optima exploiting differential evolution’s niching capability,” in IEEE Symposium on Differential Evolution, 2011. SDE 2011. (IEEE Symposium Series on Computational Intelligence), Paris, France, April 2011, p. 80–87.9
TABLE IIPEAK RATIOS AND SUCCESS RATES OF THE DE/NRAND/1/BIN ALGORITHM.Accuracy level εF5 (2D) SR10￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼PR1.000 1.000 1.000 1.000 1.000￼1.0E-01 ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ 1.000 1.0E-02 ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ 1.000 1.0E-03 ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ 1.000 1.0E-04 ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ 1.000 1.0E-05 ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ 1.0001.000 1.000 1.000 1.000 1.0001.000 1.000 1.000 1.000 1.0001.000 1.000 1.000 1.000 1.0001.000 1.000 1.000 1.000 1.0001.000 1.000 1.000 1.000 1.0001.000 1.000 1.000 1.000 1.0001.000 1.000 1.000 1.000 1.000￼￼￼￼￼￼Accuracy level εF8 (2D) SRF6 (2D)F7 (2D)F6 (3D)F7 (3D)￼￼￼￼￼￼￼￼￼￼￼PR1.000 1.000 0.998 1.000 1.000PRSRPRSRPRSRPRSR￼1.0E-01 ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ 1.000 1.0E-02 ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ 1.000 1.0E-03 ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ 0.980 1.0E-04 ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ 1.000 1.0E-05 ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ 1.0000.450 0.438 0.440 0.434 0.0000.000 0.000 0.000 0.000 0.0000.347 0.346 0.349 0.337 0.3330.000 0.000 0.000 0.000 0.0000.108 0.105 0.113 0.112 0.1130.000 0.000 0.000 0.000 0.0000.097 0.095 0.099 0.095 0.0940.000 0.000 0.000 0.000 0.000￼￼￼￼￼￼Accuracy level εF12 (3D) SRF9 (2D)F10 (2D)F11 (2D)F11 (3D)￼￼￼￼￼￼￼￼￼￼￼PR0.522 0.535 0.507 0.502 0.507PRSRPRSRPRSRPRSR￼1.0E-01 ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ 0.000 1.0E-02 ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ 0.000 1.0E-03 ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ 0.000 1.0E-04 ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ 0.000 1.0E-05 ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ 0.0000.683 0.673 0.683 0.673 0.6700.000 0.000 0.000 0.000 0.0000.855 0.837 0.815 0.815 0.7770.240 0.220 0.140 0.160 0.1000.667 0.667 0.667 0.667 0.6670.000 0.000 0.000 0.000 0.0000.667 0.667 0.667 0.667 0.6670.000 0.000 0.000 0.000 0.000￼￼￼￼￼￼Accuracy level εF12 (20D) SRF11 (5D)F12 (5D)F11 (10D)F12 (10D)￼￼￼￼￼￼￼￼￼￼￼PRSRPRSRPRSRPRSRPR￼1.0E-01 ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ 0.000 1.0E-02 ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ 0.000 1.0E-03 ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ 0.000 1.0E-04 ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ 0.000 1.0E-05 ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ 0.000TABLE IIIPEAK RATIOS AND SUCCESS RATES OF THE CROWDING DE/RAND/1/BIN ALGORITHM.0.677 0.663 0.663 0.663 0.6570.000 0.000 0.000 0.000 0.0000.345 0.325 0.295 0.290 0.2870.000 0.000 0.000 0.000 0.0000.403 0.343 0.323 0.270 0.2500.000 0.000 0.000 0.000 0.0000.227 0.167 0.152 0.125 0.1270.000 0.000 0.000 0.000 0.0000.130 0.127 0.130 0.125 0.123￼￼￼￼￼￼￼￼￼Accuracy level εF5 (2D) SRF1 (1D)F2 (1D)F3 (1D)F4 (2D)￼￼￼￼￼￼￼￼￼￼￼PR1.000 1.000 1.000 1.000 1.000PRSRPRSRPRSRPRSR￼1.0E-01 ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ 1.000 1.0E-02 ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ 1.000 1.0E-03 ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ 1.000 1.0E-04 ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ 1.000 1.0E-05 ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ 1.0001.000 0.710 0.090 0.020 0.0001.000 0.500 0.000 0.000 0.0001.000 1.000 1.000 1.000 1.0001.000 1.000 1.000 1.000 1.0001.000 1.000 1.000 1.000 1.0001.000 1.000 1.000 1.000 1.0001.000 1.000 1.000 0.995 0.4201.000 1.000 1.000 0.980 0.040￼￼￼￼￼￼Accuracy level εF8 (2D) SRF6 (2D)F7 (2D)F6 (3D)F7 (3D)￼￼￼￼￼￼￼￼￼￼￼PR1.000 1.000 1.000 1.000 1.000PRSRPRSRPRSRPRSR￼1.0E-01 ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ 1.000 1.0E-02 ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ 1.000 1.0E-03 ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ 1.000 1.0E-04 ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ 1.000 1.0E-05 ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ 1.0001.000 0.999 0.972 0.107 0.0001.000 0.980 0.740 0.000 0.0000.703 0.724 0.715 0.709 0.7160.000 0.000 0.000 0.000 0.0000.847 0.835 0.716 0.290 0.0380.000 0.000 0.000 0.000 0.0000.271 0.272 0.274 0.274 0.2700.000 0.000 0.000 0.000 0.000￼￼￼￼￼￼Accuracy level εF12 (3D) SRPR1.000 1.000 1.000 1.000 1.000F1 (1D)F9 (2D)SRPRF2 (1D)F10 (2D)SRPRF3 (1D)F11 (2D)SRPRF4 (2D)F11 (3D)SR￼￼￼￼￼￼￼￼￼￼￼PR0.730 0.690 0.627 0.490 0.375PRSRPRSRPRSRPRSR￼1.0E-01 ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ 0.000 1.0E-02 ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ 0.000 1.0E-03 ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ 0.000 1.0E-04 ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ 0.000 1.0E-05 ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ 0.0000.937 0.690 0.667 0.667 0.6670.720 0.040 0.000 0.000 0.0000.380 0.055 0.007 0.007 0.0020.000 0.000 0.000 0.000 0.0000.837 0.683 0.667 0.667 0.6670.400 0.020 0.000 0.000 0.0000.683 0.667 0.667 0.667 0.6670.000 0.000 0.000 0.000 0.000￼￼￼￼￼￼Accuracy level εF12 (20D) SRF11 (5D)F12 (5D)F11 (10D)F12 (10D)￼￼￼￼￼￼￼￼￼￼￼PRSRPRSRPRSRPRSRPR￼1.0E-01 ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ 0.380 1.0E-02 ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ 0.000 1.0E-03 ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ 0.000 1.0E-04 ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ 0.000 1.0E-05 ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ ￼ 0.0000.697 0.667 0.667 0.667 0.6670.000 0.000 0.000 0.000 0.0000.567 0.425 0.280 0.115 0.0470.080 0.000 0.000 0.000 0.0000.517 0.250 0.200 0.173 0.1700.080 0.000 0.000 0.000 0.0000.000 0.000 0.000 0.000 0.0000.000 0.000 0.000 0.000 0.0000.502 0.013 0.000 0.000 0.000￼￼</Text>
        </Document>
        <Document ID="16">
            <Title>Benchmark and Comparison</Title>
            <Text>test</Text>
        </Document>
        <Document ID="22">
            <Title>ihaka_98</Title>
            <Text>AbstractR began as an experiment in trying to use the meth- ods of Lisp implementors to build a small testbed which could be used to trial some ideas on how a statistical environment might be built. Early on, the decision was made to use an S-like syntax. Once that decision was made, the move toward being more and more like S has been irresistible.R has now outgrown its origins and its development is now a collaborative effort undertaken using the Internet to exchange ideas and distribute the results. The focus is now on how the initial experiment can be turned into a viable piece of free software.This paper reviews the past and present status of R and takes a brief look at where future development might lead.1 GenesisA long time ago I discovered a wonderful book by Hal Abelson and Gerald Sussman called The Structure and Interpretation of Computer Programs. The book aims to introduce engineering students to computing using the Scheme programming language. It presents a wonderful view of programming; investigating a wide variety of in- teresting and practical examples, and even showing how a language like Scheme can be implemented.At about the same I obtained access to one of the first releases of Rick Becker and John Chambers’ New S language. I remember noticing both similarities and differences between S and Scheme. In particular, I re- member that one day I wanted to show Alan Zaslavsky how you could use lexical scope to obtain own variables. I didn’t have a copy of Scheme handy, so I tried to show him using S. My demonstration failed because of the dif- ferences in the scoping rules of S and Scheme. It left methinking that there were useful additions which could be made to S.Rather later, Robert Gentleman and I became col- leagues at The University of Auckland. We both had an interest in statistical computing and saw a common need for a better software environment in our Macin- tosh teaching laboratory. We saw no suitable commer- cial environment and we began to experiment to see what might be involved in developing one ourselves.It seemed most natural to start our investigation by working with a small Scheme-like interpreter. Because it was clear that we would probably need to make sub- stantial internal changes to the interpreter we decided to write our own, rather than adopt one the many free Scheme interpreters available at the time. This is not quite as daunting a task as it might seem. The process is well mapped out in books such as that of Abelson- Sussman and that of Kamin. Having access to the source code of a number Scheme interpreters also helped with some of the concrete implementation details.Our initial interpreter consisted of about 1000 lines of C code and provided a good deal of the language func- tionality found in the present version of R. To make the interpreter useful, we had to add data structures to sup- port statistical work and to choose a user interface. We wanted a command driven interface and, since we were both very familiar with S, it seemed natural to use an S-like syntax.This decision, more than anything else, has driven the direction that R development has taken. As noted above, there are quite strong similarities between Scheme and S, and the adoption of the S syntax for our interpreter produced something which “felt” remarkably close to S. Having taking this first step we found ourselves adopting more and more features from S.Despite the similarity between R and S, there remain number of key differences. The two fundamental differ-R : Past and Future HistoryA Draft of a Paper for Interface ’98Ross Ihaka Statistics Department The University of Auckland Auckland, New Zealand
&gt; total &lt;- 10&gt; make.counter &lt;-+++++}&gt; counter &lt;- make.counter() &gt; counter()[1] 1&gt; counter()[1] 2&gt; counter()[1] 3Figure 1: A simple function demonstrating how the scoping rules in R differ from those of S.function(total = 0)  function() { total &lt;&lt;- total + 1totalences result from R’s Scheme heritage.• Memory Management: In R, we allocate a fixed amount of memory at startup and manage it with an on-the-fly garbage collector. This means that there is very little heap growth and as a result there are fewer paging problems than are seen in S.• Scoping: In S, variables in functions are either lo- cal or global. In R we allow functions to access to the variables which were in effect when the function was defined; an idea which dates back to Algol 60 and found in Scheme and other lexically scoped lan- guages. Consider the function definition in figure 1. The function make.counter returns a value which is itself a function. This “inner function” increments the value of the variable total, and then returns the value of that variable. In S, the variable being manipulated is global. In R, it is the one which is in effect when the function is defined; i.e. it is the argument to make.counter. The effect is to create a variable which only the inner function can see and manipulate.Generally, the scoping rules used in R have met with approval because they promote a very clean pro- gramming style. We have retained them despite the fact that they complicate the implementation of the interpreter.The two differences noted above are of a very basic na- ture. In addition, we have experimented with a number of other features in R. A good deal of the experimenta- tion has been with the graphics system (which is quite similar to that of S). Here is a brief summary of some of these experiments.• Colour Model: R uses a device independent 24-bit model for colour graphics. Colours can be specified in a number of ways.1. By specifying the levels of red, green and blue primaries which make up the Colour. For ex- ample, the string "#FFFF00" indicates full in- tensity for red and green with no blue; produc- ing yellow.2. By giving a colour name. R uses the colour naming system of the X Window Sys- tem to provide about 650 standard colour names, ranging from the plain "red", "green" and "blue" to the more exotic "light goldenrod", and "medium orchid 4".3. As a index into a user settable colour table. This provides compatibility with the S graphics system.• Line Texture Description: Line textures can also be specified in a flexible fashion. The specification can be:1. A texture name (e.g. "dotted").2. A string containing the lengths for the pen up/down segments which compose a line. For example, the specification "52" indicates 5 points (or pixels) with “pen down” followed by 2 with “pen up”, with the pattern replicated for the length of the line.3. An index into a fixed set of line types, again providing compatibility with S.• Mathematical Annotation: Paul Murrell and I have been working on a simple way of producing2
￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼0.0 0.1 0.2 0.3 0.4 0.5 Frequency λFigure 2: A plot of the periodogram of a white-noisemathematical annotation in plots. Mathematical annotation is produced by specifying an unevalu- ated R expression instead of a character string. For example,               expression(x^2+1)can be used to produce the mathematical expression x2 + 1as annotation in a plot.The annotation system is relatively simple, and not designed to have the full capabilities of a system such as TEX. Even so, it can produce quite nice results. Figure 2 shows a simple example of a time series periodogram plot produced in R. The plot was produced with a single R command which used expression to describe the labels.• Flexible Plot Layouts: A part of his PhD re- search, Paul Murrell has been looking at a scheme for specifying plot layouts. The scheme provides a simple way of specifying how the surface of the graphs device should be divided up into a numbertime series, showing the use of mathematical annotation.of rectangular plotting regions. The regions can be constrained in a variety of ways. Paul’s original work was in Lisp, but he has implemented a use- ful subset to R.These graphical experiments were carried out at Auck- land, but others have also bound R to be an environment which can be used as a base for experimentation.• Compilation: Luke Tierney has performed some experiments to see what kind of performance gains could be obtained by using byte-code compilation of R. His experiments indicated that a speed-up by a factor of 20 might be possible for some interpreted code. As yet, the internal data structures in R are probably not stable enough to make it worthwhile to follow up on this work.• WWW Interface: Jeff Banfield has developed RWeb, which is a WWW based interface to R.• Tcl/Tk Interface: Very recently Balasubrama- nian Narasimhan has begun looking into how Tcl/Tk might be used to add a fully graphical user interface to R.3log I(T)(λ) 10 XX–4 –3 –2 –1 0 1 2
2 A Free Software Project 2.1 A Brief HistoryThe initial work on R by Robert Gentleman and I pro- duced what looked like a potentially useful piece of soft- ware and we began preparing it for use in our teaching laboratory. We were heartened enough by our progress to place some binary copies of R at Statlib and make a small announcement on the s–news mailing list in Au- gust of 1993.A number of people picked up our binaries and of- fered feedback. The most persistent of these was Martin Ma ̈chler of ETH Zurich, who encouraged us to release the R source code as “free software”.We had some initial doubts about doing this, but Mar- tin’s arguments were persuasive, and we agreed to make the source code available by ftp under the terms of the Free Software Foundation’s GNU general license. This happened in June of 1995.At this point, the development of R was a relatively closed process. Robert and I (soon joined by Martin) would get bug reports by e-mail and from time-to-time release updated versions of R. We quickly noticed that there was no real forum for users to discuss R with each other and so we began maintaining a small mailing list.As interest in R grew (mostly by word of mouth) it became clear that manually maintaining the mailing list was not an effective option. Worse than that, at Auck- land we were paying for e-mail, and the cost was be- ginning to become noticeable. Eventually Martin vol- unteered the use of facilities at ETH Zurich to establish automated mailing lists to carry discussions about R and R development. In March of 1996 the r–testers mailing list was started. Roughly a year later this was replaced with three newsgroups: r–announce, r–help and r–devel.As R developed and people began porting applications to it, it became clear that we needed a better distribu- tion mechanism. After some discussion it was decided a formal archive mechanism was desirable. Kurt Hornik of TU Wien took on the task of establishing the archive. In addition to the master site in Austria there are a number of mirror sites, including StatLib.With the introduction of the mailing lists, develop- ment on R accelerated. This was partly because we ob- tained many more reports and suggestions and partly because we also began to receive patches and code con- tributions. The contributions ranged from fixes for typos through to changes which provided substantial increases in functionality and performance.The level of contribution was such that Robert, Mar- tin and I couldn’t always make changes at a rate which was satisfactory to those asking for changes. As a re-sult, in mid-1997 we established a larger “core group” who can make changes to the source code CVS archive. This group currently consists of:Doug Bates, Peter Dalgaard, Robert Gentleman, Kurt Hornik, Ross Ihaka, Friedrich Leisch, Thomas Lumley, Martin Ma ̈chler, Paul Murrell, Heiner Schwarte, and Luke Tierney.Since all work on R is strictly of a voluntary nature, the organisation is very loose, with members contributing when and as they can.2.2 ContributorsWhen Robert and I started work on R, we were hopeful that we might be able to produce something we could use to teach our introductory data analysis courses. Had we continued to work strictly on own it is likely that this is precisely what we would have achieved.The decision to make R free software has enabled us to set rather higher goals, because it has given us access to a large pool of very talented individuals who have been willing to invest significant effort in the project. Indeed, one of the very best things about having worked on R has been the chance to work with such a great group of people.In addition to the core group listed above, I would like to acknowledge the following individuals who have made significant contributions to R.Valerio Aimale, Ben Bolker, John Chambers, Simon Davies, Paul Gilbert, Arne Kovac, Philippe Lambert, Alan Lee, Jim Lindsey, Patrick Lindsey, Mike Meyer, Martyn Plummer, Anthony Rossini, Bill Venables, Gregory Warnes, and mward@wolf.hip.berkeley.edu(I apologise for omissions here. Our record keeping has not been all that it could be).In addition a host of other individuals have made con- tributions.2.3 Present StatusR is still under active development and there is still some work needed before it can be considered ready for widespread use. In particular, some changes will be required to support moderate to large-sized data sets.4
More importantly, there is an almost complete lack of introductory documentation, although much of what has been written about S directly applicable to R.Despite this, it seems that R is beginning to reach the point where it is stable enough for regular use (at least under Unix). I am hopeful that during the next year we can release a complete R version 1.0 package as part of the Free Software Foundation’s GNU suite of software.3 The Future 3.1 RIt is the present aim of the R project to produce a free implementation of something “close to” version 3 of the S language and to provide ongoing support and mainte- nance for the resulting software. Some members of the R core have proposed that future developments in S ver- sion 4 should be also tracked. At this point it is unclear whether this will happen.One development which would help R a good deal would be the development of an integrated graphical user interface. Some initial work has begun on this and I be- lieve that it is something which will come quite quickly.My personal future interest in R is mainly as a user. Given the investment I have made in it, I hope that I will be able to get substantial use out of R for statistical work and teaching.3.2 Related WorkWorking on R has shown me that there a number of interesting questions related to building statistical soft- ware. My own conclusion has been that it is important to pursue efficiency issues, and in particular, speed.As noted in section 1, Luke Tierney performed some experiments with R to see what kind of speed increase could be obtained using byte-code compilation; the in- dications were that a speedup by a factor of 20 might be possible for some computations.There is other evidence that a factor of 100 (roughly the speed of unoptimised C) might be possible with com- pilation to native machine code. With this level of per- formance, there would be no need for any foreign func- tion interface and all computations could take place in a single language environment.I am intrigued by what such an environment might offer. An increase in performance of this magnitude is likely to produce a qualitative change in the use it gets puts to.The difficulty is that the creation of such a compiled environment requires the hand of an expert in compila-tion. There is a real problem in finding such an expert who is also aware of the type of problems which statis- ticians handle.4 AcknowledgementsIt goes without saying that R would not exist without the pioneering work of John Chambers and his AT&amp;T collaborators. John has changed the way that many of us think about statistical computing and the fact that R has evolved to resemble S as closely as it does is is a testimony to the extent that people enjoy doing data analysis with S.The Free Software Movement (or movements perhaps) has been another major source or ideas and influence on R. I do my development work on a workstation which runs the FreeBSD operating system and is equipped with a rich set of development tools from the Free Software Foundation. Hopefully, R represents some pay back to the free software community for what they have provided to me and the other R developers.Finally, I’d like to acknowledge my partner-in-crime; Robert Gentleman. During our work on R we have prac- tically lived in one another’s back pockets. It speaks vol- umes that, not only are we still on speaking terms, but we still go out for beer together on Friday evenings.ReferencesAbelson, H. and G. J. Sussman, with J. Sussman (1985). Structure and Interpretation of Computer Programs. Cambridge MA: MIT Press.Becker, R. A., Chambers, J. M. and Wilks, A. R. (1986). The new S Language: A programming environ- ment for data analysis and graphics. Pacific Grove, CA: Wadsworth &amp; Brooks/Cole.Chambers, J. M. and T. J. Hastie, Eds. (1991). Sta- tistical Models in S. Pacific Grove, CA: Wadsworth &amp; Brooks/Cole.R. Gentleman and R. Ihaka (1997). “The R language”, In Proceedings of the 28th Symposium on the Interface, L. Billard and N. Fisher Eds. The Interface Foundation of North America.Ihaka, R. and R. Gentleman (1996). “R: A language for data analysis and graphics,” Journal of Computational and Graphical Statistics, 5, 299–314.Kamin, S. N. (1990). Programming languages. Addison Wesley.5</Text>
        </Document>
        <Document ID="12">
            <Title>General Function</Title>
            <Text>Starting point of the project was the paper provided by Jonathen E. Fieldsend [#fieldsend_2014] on the Niching Migratoy Multi-Swarm Optimiser (NMMSO) algorithm. NMMSO is a multi-modal optimiser which relies heavily on multiple swarms which are generated on the landscape of an algorithm in order to find the global optimum. It is build around three main pillars: (1) dynamic in the numbers of dimensions, (2) self-adaptive without any special preparation and (3) exploitative local search to quickly find peak estimates [p. 1][#fieldsend_2014]. 

Multi-modal optimization in general is not that different from well known and widely discussed single-objective optimisation, but in difference to it the goal of the algorithms in the multi-modal is not to find just one single optimizing point but all possible points [p. 1][#fieldsend_2014]. In order to do so, many early multi-modal optimization algorithms needed highly defined parameters [TODO: quote needed]. 

Newer algorithms fall in the field of self-tuning and try to use different mathematical paradigms like nearest-best clustering with covariance matrices [#preuss_2010] and strategies like storing the so far best found global optima estimators to provide them as parameters for new optimization runs [#epitropakis_2013]. Contradictory to that NMMSO goes another way and uses the the swarm strategy in order to find which store their current [#fieldsend_2014]

In order to do so NMMSO follow a strict structure which can be seen in the following pseudo-code
	
	nmmso(max_evals, tol, n, max_inc, c_1, c_2, chi, w)
		S: initialise_swarm(1)
		evaluations := 1
		while evaluations &lt; max_evals:
			while flagged_swarms(S) == true:
				{S, m} := attempt_merge(S, n, tol)
				evals := evals + m
			S := increment(S, n, max_inc, c_1, c_2, chi, w)
			evals := evals + min(|S|, max_inc)
			{S, k} := attempt_separation(S, tol)
			evals := evals + k
			S := add_new_swarm(S)
			evals := evals + 1
		{X*, Y*} := extract_gebsest(S)
		return X*,Y*</Text>
        </Document>
        <Document ID="5">
            <Title>Structure</Title>
            <Text>### Seminar Project - R Implementation of NMMSO 
1. Introduction
2. Explanation of the Algorithm &amp; Problem
	1. General function &amp; Pseudcode
	2. CEC
3. Our implementation of the programm
	1. Structure of the project
	2. Pitfalls &amp; Problems
	4. Benchmark &amp; Comparison
	5. Testing &amp; alternative parameter settings
4. Discussion
5. Conclusion
	</Text>
        </Document>
        <Document ID="17">
            <Title>Testing and alternative parameter settings</Title>
            <Text>test</Text>
        </Document>
        <Document ID="23">
            <Title>running_up_those_hills_2014</Title>
            <Text>Running Up Those Hills: Multi-Modal Search with the Niching Migratory Multi-Swarm OptimiserJonathan E. FieldsendCollege of Engineering, Mathematics and Physical Sciences University of ExeterExeter, UK, EX4 4QFEmail: J.E.Fieldsend@exeter.ac.ukAbstract—We present a new multi-modal evolutionary opti- miser, the niching migratory multi-swarm optimiser (NMMSO), which dynamically manages many particle swarms. These sub- swarms are concerned with optimising separate local modes, and employ measures to allow swarm elements to migrate away from their parent swarm if they are identified as being in the vicinity of a separate peak, and to merge swarms together if they are identified as being concerned with the same peak. We employ coarse peak identification to facilitate the mode identification required. Swarm members are not constrained to particular sub- regions of the parameter space, however members are initialised in the vicinity of a swarm’s local mode estimate. NMMSO is shown to cope with a range of problem types, and to produce results competitive with the state-of-the-art on the CEC 2013 multi-modal optimisation competition test problems, providing new benchmark results in the field.I. INTRODUCTIONAn effective multi-modal optimiser embodies a number of traits: (1) it is dynamic in the number of modes it maintains and returns, enabling it to be applied to problems with few or many modes; (2) it is self-adaptive, with few meta-parameters, enabling a wide range of problem types to be tackled without prior tuning; (3) it incorporates exploitative local search, enabling it to rapidly hone the peak estimates it is maintaining. Although the algorithm genus may vary (genetic algorithm, evolutionary strategy, particle swarm, differential evolution, etc.), it is these three properties which all the best-performing algorithms in the CEC 2013 competition contain [1]. Here we present a new optimiser which embeds the three properties listed above, and utilises multiple particle swarm optimisers to rapidly climb peaks in the search landscape. The swarms do not operate in isolation: elements can migrate away from their parent swarm if they are judged to have discovered a separate peak. Swarms may also be merged if they are identified as converging on the same peak. Additionally, swarm members are not constricted to movements within a local region of design space.The paper proceeds are follows. In Section II we describe the general multi-modal optimisation problem, and highlight the difficulties that confront optimisers in this arena. In Section III we briefly discuss some of the popular evolutionary com- putation approaches to multi-modal optimisation. In Section IV we introduce the niching migratory multi-swarm optimiser (NMMSO), describing its properties and relationship to otherapproaches. This is followed by empirical results on the CEC 2013 competition test problems. The paper ends with a discussion in Section VI.II. MULTI-MODAL OPTIMISATIONThe general aim in multi-modal optimisation is similar to standard uni-objective optimisation, that is, given a legal search domain X, without loss of generality, we seek to maximise f(x), x ∈ X, given any equality and inequality constraints. In the case of a multi-modal problem however, we seek not simply to discover a single design x which maximises f(x) given the constraints, but all x∗ ∈ X which obtain the maximum possible function response, but which inhabit isolated peak regions. That is, the mapped objective values in the immediate region of an x∗ are all equal or lower than f(x∗). Local optima (local modes/peaks) in contrast are locations which are surrounded in the immediate vicinity with less ‘fit’ solutions (lower responses from f(·)), but which do not themselves have the highest possible fitness obtainable. Local regions around a peak are often called niches.There are many reasons that the problem owner may wish multiple mode solutions to be discovered rather than a single ‘best’ solution. By discovering a range of different designs which are operationally equivalent insight into the problem domain may be extracted. Also, it may transpire that some designs are not machinable – i.e., X is misspecified, and therefore a range of solutions mitigates against this. Finally f(·) may be in error in certain regions, therefore a wide range of good solutions can be helpful if the ‘best’ design does not perform as emulated (it is useful to have local optima, not just global optima stored – as there is no guarantee that all the global optima under f(·) are not in error).III. EVOLUTIONARY MULTI-MODAL OPTIMISERSOne of the earliest approaches to evolutionary multi-modal optimisation is derived from the fitness sharing concept, first introduced in [2]. This was later refined as a means to partition a genetic algorithm search population into different subpopulations based on their fitness [3]. An overview of these general niching ideas is presented in [4].As highlighted in e.g. [5], many early multi-modal optimis- ers tended to be highly parametrised, relying on well-chosen values to perform well (for instance specifying a priori what
the niche width should be set as, or how many modes to search for). However, a recent design trend of the most effective multi-modal optimisers is to make them to a large degree ‘self- tuning’.The current state-of-the-art (based upon the results of the CEC 2013 competition in the field) rely on a range of different technologies and heuristics to maintain, search for and exploit mode estimates. The optimiser that was the best performing overall, proposed in [6], utilises the covariance matrix adapta- tion evolution strategy (CMA-ES) of [7]. Rather than selecting the restart location at random, [6] used nearest-better clustering to partition a search population into sub groups concerned with different modes. This is facilitated by fitting a spanning tree on the population, linking all population members to their nearest neighbour (in design space) which is better performing under f(·), and disconnecting the longest edges (thus assuming that the best search points on different peaks are likely to be further away from each other than neighbours on the same peak). This leads to another property of this approach – it is dynamic in the number of modes it maintains and returns (although limited to a maximum number, set a priori). The second best performing multi-modal optimiser [8] also has dynamic mode maintenance, storing an external dynamic archive of estimated mode locations which supports a reinitialisation mechanism, along with an adaptive control parameter technique for the differential evolution algorithm driving the search. The third best was the standard CMA-ES algorithm. Finally, the fourth ranked algorithm proposed by [9] uses an external memory to store the current global optima, along with an adaptive niche radius to mitigate the effect of setting this parameter a priori to a value which may not be appropriate to the problem at hand. A mesh of solutions is exploited, with a combination method that generates solutions in the direct of nearest (estimated) global optima.The published ranking of these algorithms is derived from their average performance on the twenty problem formulations used in the CEC 2013 benchmark suite, averaged across five different accuracy levels for fixed numbers of function evaluations. Given different test problems, and/or a different number of permitted function evaluations and accuracy levels, there may of course be a different ranking obtained. The top ranked algorithms do however possess a number of similar characteristics which would seem to describe an effective multi-modal optimiser, namely: self-adaption of search pa- rameters, dynamic mode maintenance, and exploitative local search. Here we leverage and develop these ideas, and build on aspects of our recent work in the area, which use coarse mode region identification in conjunction with local surrogates and hill-climbers [10], [11].IV. USING MULTIPLE SWARMSParticle swarm optimisation PSO has gained widespread popularity since its introduction in [12] for the optimisation of continuous non-linear functions, due to its rapid con- vergence properties on a wide range of problems, and its relative simplicity (and therefore ease of implementation). Afixed population of solutions is used, where each solution (or particle) is represented by a point in D-dimensional design space. The ith particle is commonly represented as xi = (xi,1 , xi,2 , . . . xi,D ), and its performance is evaluated on a given problem and stored. Each particle maintains knowledge of its best previous evaluated position, represented as pi (commonly referred to as ‘pbest’), and also has knowledge of the single best solution found so far in some defined neighbourhood, gi (commonly referred to as ‘gbest’). Often this is with respect to a global neighbourhood (all particles are considered), however other neighbourhood definitions can also be used. The rate of position change of a particle then depends upon its previous personal best position and the neighbourhood best, and its previous velocity. For particle i this velocity is vi = (vi,1 , . . . , vi,D ), typically initialised at random in X . The general algorithm for the adjustment of these velocities is:vi,j := ωvi,j + c1r1(bi,j − xi,j) + c2r2(gi,j − xi,j), (1) and the position is updated as:xi,j:=xi,j+χvi,j, j=1,...,D, (2)where ω, c1, c2, χ ≥ 0. ω is the inertia of a particle, c1 and c2 are constraints on the velocity toward local best and neighbourhood best - referred to as the cognitive and social learning factors respectively, χ is a constraint on the overall shift in position, and r1,r2 ∼ U(0,1). In [12], the final model presented has w and χ set at 1.0 and c1 and c2 set at 2.0.As discussed in [13], in this classical form of PSO each particle xi is flown toward pi, gi and vi. This, in effect, means that a hypercuboid is generated in design space, the bounds of which are the sum of the distances from xi to the other three points (weighted by the appropriate multiplier constants from (1) and (2)). The length of the jth dimension of the containing hypercuboid of xi is:lj = χ(wvi,j + c1(bi,j − xi,j) + c2(gi,j − xi,j)). (3)A particle xi can therefore effectively move to any point within this hypercuboid (determined by the draws of r1 and r2), but not outside of it. Note – depending on the values of χ, c1 and c2, it is possible for one or more of vi, pi and gi to lie outside this bounded region, and the higher the inertia, the more exploratory the search. As regions of the hypercuboid may lie outside of X, a PSO implementation must have a mechanism to deal with potential movements outside the legal bounds. We use rejection sampling here – i.e. r1 and r2 are resampled until a legal xi results.Here we exploit the swarm paradigm for multi-modal op- timisation. However, instead of employing a single swarm optimiser and using neighbourhood topology to maintain modes (e.g. [5]), we use multiple swarms – each of which is concerned with optimising a particular mode estimate that has been identified in the search landscape. The approach taken differs from other multi-swarm work for multi-modal problems (e.g. [14]), in that the sub-swarms do not take a “devour and move on approach”, but instead concern themselves solely
with the improvement of their local peak estimate, from the time of that particular swarm’s initialisation, until the algorithm termination (or its merging with another swarm). Unlike other sub-swarm work which use distributed swarms (e.g. [15]) the number of swarms is dynamic, and expends far fewer evaluations on niche detection.The basic idea is that NMMSO manages a number of swarms which have strong local search, and which ‘fine- tune’ their local mode estimates each generation. Additionally, on each generation swarms which have improved their mode estimate are paired with their closest adjacent swarm to see if they should merge (thus preventing duplication of labour). New regions in which to search for modes are identified by splitting away particles from existing swarms, and via random search and crossover.A high level description of the algorithm can be found in Figure 1. The algorithm takes in four overarching parameters: max evals, tol, n and max inc, alongside the standard PSO parameters which are used by all the sub-swarms. The param- eter max evals sets the total number of permissible function evaluations. tol is a small tolerance value, which specifies the Euclidean distance in design space where two peak estimates (and associated swarms) are automatically merged (we use 10−6 in our experiments here). n is the maximum number of particles in any swarm, and max inc is the maximum number of swarms to increment per algorithm iteration.The algorithm starts by generating and evaluating a single solution at random within X , making the initial swarm (Figure 1, line 1). The algorithm then continues in an optimisation loop, until the allocated function evaluations are exhausted. Line 4 checks if any swarms are flagged. This will be the case if their gbest (mode estimate) has changed in the last algorithm iteration, or if the swarm has just resulted from the merging of two previous swarms. Those swarms that have been marked are compared to their nearest neighbour (based on the Euclidean distance between their respective gbests locations in design space). If the nearest neighbour is within tol distance, then the swarms are automatically merged, if not, then the mid-point in design space between the gbest locations is evaluated. If this location is worse than both of the swarm gbests, the pair are maintained separately – if not they are merged. The variable m tracks how many mid-points have been evaluated each time the routine is called. Sampling along a line for peak detection is not new (being introduced in [16]) – however typically multiple points are sampled each time, and the detection procedure is regularly undertaken (e.g. [16], [15]), consuming the majority of function evaluations during an optimisation. In contrast, NMMSO uses only a small fraction of its function evaluations on line sampling.When merging swarms, if the total number of particles in both swarms is less than, or equal to, the swarm limit n, then the resultant swarm simply contains all the elements of both swarms. If however the total number of elements in both exceeds n, then the fittest n particles across both swarms are used to create the merged swarm, with the remaining particles being discarded.Require: max ￼ evals, tol, n, max ￼ inc, c1, c2, χ, ω 1: S := initialise_swarm(1)2: evals:=13: while evals &lt; max evals do4: while flagged_swarms(S) = true do 5: {S, m} := attempt_merge(S, n, tol) 6: evals := evals + m7: end while8: S := increment(S, n, max inc, c1, c2, χ, ω)9: evals := evals + min(|S|, max inc)10: {S, k} := attempt_separation(S, tol) 11: evals := evals + k12: S := add_new_swarm(S)13: evals := evals + 114: end while15: {X ∗ , Y ∗ } := extract_gbest(S )16: return X∗,Y∗Fig. 1. High-level pseudocode of NMMSO.The evaluation of a mid-point between two mode estimate locations is a coarse way of mode region identification. There are a number of landscape conditions where it will identify two solutions as lying on different peaks when they are in fact on the same mode. This may occur if there is a ridge curving away and then back joining the two points, or when a point ‘lower down’ on the same peak region is closer to a point on another mode, than a point lying ‘further up’ on the same mode. This means the point lower down will be paired for comparison with the point on the other mode, resulting in both the mode estimates lying on different parts of the same peak region being maintained as gbests for distinct swarms. However, as the swarms optimise and improve their gbests (move up the peaks), mode estimates will move to positions where their relationship is correctly identified (resulting in merging).After merging has been attempted, each swarm is incre- mented (line 8). If a swarm has fewer than n particles, then a single new particle is added to the swarm and evaluated. This new entrant is sampled uniformly in a hypersphere centred on the swarm’s current peak estimate (its gbest), with the radius corresponding to half the distance to the nearest neighbouring swarm peak estimate (subject to the sample lying in X ). The velocity is sampled in a similar fashion (but centred on 0, without having to lie in X ). Note that although the particles are initialised within this local region, their subsequent movement is not restricted (beyond staying in X). If a swarm has reached its full quota of n particles, then on incrementing the swarm one of its particles is selected at random, and updated according to (1) and (2). The number of swarms incremented each generation is limited to max inc – if the number of swarms maintained exceeds this value, then 50% of the time the max inc swarms with the best gbests are incremented, the other 50% of the time max inc swarms are selected at random for incrementing. This limit is to prevent￼￼￼￼￼￼￼￼￼￼
TABLE IPARAMETERS USED FOR PERFORMANCE MEASUREMENT, AND MAXIMUM NUMBER OF FUNCTION EVALUATIONS PER OPTIMISER RUN.V. EMPIRICAL RESULTSThe NMMSO algorithm is compared to the results of a wide range of multi-modal optimisation algorithms [17], [7], [18], [8], [19], [20], [21], [6], [9], [22], which were applied to the 20 benchmark problems of the CEC 2013 “Competition on Niching Methods for Mutlimodal Optimization” [23], [1]. We follow the algorithm assessment protocol used in the CEC 2013 competition; our results can therefore be directly compared to the combined competition results.We also compare to the Multinational Evolutionary Algo- rithm (MEA) [16] and Multi-Sub-Swarm Particle Swarm Op- timisation Algorithm (MSSPSO) [15] – as these both embed ‘hill-valley’ approaches to niche maintenance. Parameters for these comparison algorithms are fixed as in their respective original publications. In [16] the population size is varied across test problems from 750-1500, we use 1000 for all test problems here. Likewise in [15] population size varied from 1-40 and number of sub-swarms from 5-25. In keeping with the original competition, algorithm parameters are fixed for all problems – a population size of 20 and 25 sub-swarms is used here for MSSPSO.2The 20 benchmark problems are of varying dimensionality and number of optima, and are derived from 12 base test prob- lems. The Equal Maxima (F2), Himmelblau (F4), Vincent (F7, F9) and Modified Rastrigin (F10) problems only have global peaks. The Five-Uneven-Peak Trap (F1), Uneven Decreasing Maxima (F3), Shubert (F6, F8), and Composite Functions 1 (F11), 2 (F12), 3 (F13, F14, F16, F18) and 4 (F15, F16, F19, F20) all have local maxima as well as global maxima (with the Shubert and Composite Functions having many more local maxima than global maxima). Due to space constraints formal definitions are not provided here – however a technical report detailing them can be found online [23].Additionally, NMMSO is compared to the problem level results which are published in [9] and [8] for the niching vari- able mesh optimisation (N-VMO) and the dynamic archiving niching differential evolution (dADE) algorithms.Problem assessment criteria are detailed in Table I. The parameter r gives the maximum distance (in design space) a solution may be from a peak be categorised to have found it – subject to a further accuracy level, ε, which gives the maximum distance from the global maximum in objective space. For all problems five different accuracy levels are assessed, ε = {10−1 , 10−2 , 10−3 , 10−4 , 10−5 }.All algorithms are run 50 times on each problem. Two cri- teria are used for assessment. The success rate (SR) measures the proportion of successful runs (those which find all global optima given the prescribed ε and r). A value of 1.0 indicates that all 50 runs found all global peaks, whereas a value of 0.5 indicates that half of the runs found all global peaks. The peak ratio (PR) measure gives the average proportion of global2The value of the penalty applied to swarm members who stray onto other peaks is not detailed in [15]. Here we set it such that straying particles cannot replace their pbest.￼￼Function￼F1￼￼F2F3￼￼F4￼F5￼rPeak height Max evals￼￼￼0.01 200 50k￼￼￼￼0.01 1 50k￼￼￼￼0.01 1 50k￼￼0.01 200 50k￼￼￼￼￼0.5 1.03163 50k￼￼￼Function￼F6￼￼F7F8￼￼F9￼F10￼rPeak height Max evals￼￼￼0.5 186.731 200k￼￼￼￼0.2 1 200k￼￼￼￼0.5 2709.0935 400k￼￼0.2 1 400k￼￼￼￼￼0.01 -2 200k￼￼￼Function￼F11￼￼F12F13￼￼F14￼F15￼rPeak height Max evals￼￼￼0.01 0 200k￼￼￼￼0.01 0 200k￼￼￼￼0.01 0 200k￼￼0.01 0 400k￼￼￼￼￼0.01 0 400k￼￼￼Function￼F16￼￼F17F18￼￼F19￼F20￼rPeak height Max evals￼￼￼0.01 0 400k￼￼￼￼0.01 0 400k￼￼￼￼0.01 0 400k￼￼0.01 0 400k￼￼￼￼￼0.01 0 400k￼￼￼￼￼￼￼￼￼￼￼￼￼the algorithm exhausting too many function evaluations on poor performing local modes. It biases the search toward the best max inc found so far, but still searches in the wider population of swarms, as these swarms may find substantially better solutions at a later point in time and may also provide useful particles when merging.On line 10 a single swarm is selected at random from those which are at capacity (i.e. have n elements). This is checked to see if it should have a particle removed to seed a new swarm. First a particle, xi, is selected at random from the swarm. If xi is more than tol distance from the swarm’s gbest, then the mid-point between it and the swam gbest is evaluated.1 If the performance of this mid-point is worse than f(xi), then xi is removed from its parent swarm, and used to seed a new swarm, taking its velocity with it. It is replaced in its previous swarm by the evaluated mid-point, whose velocity is initialised at random as if it was a new swarm entrant. If however the mid-point is not worse than xi, then xi remains in its original swarm, and instead the swarm’s gbest is compared to the mid-point evaluation: if it is worse, then the gbest is replaced. Very early in an optimiser run, as none of the maintained swarms has reached capacity, no mid-points are evaluated due to the attempt_separation routine (i.e. k = 0). As the optimisation progresses, typically k = 1 at each iteration, although as swarms converge on their gbest locations the randomly selected xi may be within the tol distance, and so k = 0 may still occur later in an optimisation run.Finally, each algorithm iteration ends with a new swarm being generated. 50% of the time this is seeded with a uniformly sampled location in X , otherwise it is seeded by a single offspring solution, generated using uniform crossover of two randomly chosen swarm gbests (the probability of inheriting a particular design parameter from either parent being 0.5). The generation of random swarms means the algorithm is constantly looking for new peaks in addition to those currently being optimised, and the uniform crossover means any peak symmetry in the landscape is exploited.1If it is less than tol distance away, even if it is split off, it will be merged back into the swarm on line 5 of the next iteration, so it is computationally efficient to check this beforehand.￼
￼TABLE IICONVERGENCE RATES OF NMMSO, N-VMO AND DADE/NRAND/1/BIN. BEST VALUES FOR EACH PROBLEM ARE UNDERLINED.10−1 1.000 10−2 1.000 10−3 1.000 10−4 1.000 10−5 1.0001.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 F6 F7 F8 F9 F10Algorithm dADE/nrand/1NMMSOAlgorithm dADE/nrand/1NMMSOAlgorithm dADE/nrand/1N-VMONMMSOAlgorithm dADE/nrand/1N-VMO NMMSOFunction Mean St. D. Mean St. D.F1 F2 5922 221 1673 38 578 167 135 62F11 F12 145456 114735 58240 21749 5836 49537ε = 10−1F3 F4 F5 203 3107 36714 845 12146 1191 11446 947 53 F13 F14 F15182185 219869 61965 47527 154230 16890 53038 391400 400000F6274596904 68441 42978F16292773133136F72911618 27349 14198F17200503127782F836728242450 391589 21682F18392376F9 F10 396811 3392 22547 653 399982 1422125 444 F19 F20Function Mean St. D. Mean340214400000St.D. 2872 41905 40697 36202 0 0 0 0 0 0Function Mean St. D. Mean St.D. Mean St. D.Function Mean St.D. Mean St.D. Mean St. D.F1 F2 20202 1801 2788 586 12795 31835 236 2847 1089 487 179 124F11 F12 200000 200000ε = 10−4F3 F4 F51290 12703 3567565 1668 652380 25769 13012128 265 278 0 0 0 0 24688342 1910 617131 913 149F13 F14 F15 200000 400000 4000008875940262F16 4000003135013175F17 40000039252521587F18 400000400000 2686 0 388F19 F20 400000 4000000 0 0 0 0 0 0 0 0 0 200000 200000 200000 400000 400000 400000 400000 400000 400000 400000 0 0 0 0 0 0 0 0 0 09057 68049 74120 400000 400000 400000 400000 400000 400000 400000 3261 38807 43854 0 0 0 0 0 0 0TABLE IIISUCCESS RATES OF NMMSO, N-VMO AND DADE/NRAND/1/BIN. BEST VALUES FOR EACH PROBLEM AND ACCURACY LEVEL ARE UNDERLINED.F1 F2 F3 F4 F5ε NMMSO N-VMO dADE NMMSO N-VMO dADE NMMSO N-VMO dADE NMMSO N-VMO dADE NMMSO N-VMO dADEε NMMSO N-VMO dADE NMMSO N-VMO dADE NMMSO N-VMO dADE NMMSO N-VMO dADE NMMSO N-VMO dADE 10−1 0.960 1.000 1.000 1.000 1.000 1.000 0.260 0.000 0.020 0.020 1.000 1.000 1.000 1.000 0.500 10−2 0.960 1.000 1.000 1.000 1.000 0.240 0.220 0.000 0.000 0.000 0.000 1.000 1.000 1.000 0.380 10−3 0.960 0.360 1.000 1.000 0.140 0.020 0.180 0.000 0.000 0.000 0.000 1.000 1.000 1.000 0.280 10−4 0.940 0.000 0.780 1.000 0.000 0.000 0.180 0.000 0.000 0.000 0.000 1.000 1.000 1.000 0.140 10−5 0.000 0.000 0.000 1.000 0.000 0.000 0.180 0.000 0.000 0.000 0.000 1.000 1.000 0.660 0.020F11 F12 F13 F14 F15ε NMMSO N-VMO dADE NMMSO N-VMO dADE NMMSO N-VMO dADE NMMSO N-VMO dADE NMMSO N-VMO dADE 10−1 1.000 1.000 0.640 0.980 0.220 0.980 0.960 1.000 0.140 0.080 1.000 0.700 0.000 1.000 1.000 10−2 1.000 0.000 0.000 0.980 0.000 0.440 0.960 0.000 0.000 0.060 0.000 0.000 0.000 0.020 0.000 10−3 1.000 0.000 0.000 0.980 0.000 0.000 0.940 0.000 0.000 0.020 0.000 0.000 0.000 0.000 0.000 10−4 1.000 0.000 0.000 0.980 0.000 0.000 0.940 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 10−5 1.000 0.000 0.000 0.980 0.000 0.000 0.940 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000F16 F17 F18 F19 F20ε NMMSO N-VMO dADE NMMSO N-VMO dADE NMMSO N-VMO dADE NMMSO N-VMO dADE NMMSO N-VMO dADE10−1 0.000 1.000 0.540 0.000 10−2 0.000 0.020 0.000 0.000 10−3 0.000 0.000 0.000 0.000 10−4 0.000 0.000 0.000 0.000 10−5 0.000 0.000 0.000 0.000peaks found across runs, i.e. for q runs:  q oPR= i=1 i tq1.000 0.760 0.000 0.960 0.080 0.000 0.220 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000where oi denotes the number of global optima discovered by the ith run, and t is the total number of global peaks. We use the code made available by the CEC 2013 competition organisers for representing the test problems, and for assessing algorithm performance.3We set the automatic merging tolerance tol = 10−6, the maximum swarm size n = 10D (where D is the number of design parameters) and the maximum number of swarms to increment max inc = 100. We use standard PSO parameters3 Obtainable from http://goanna.cs.rmit.edu.au/∼xiaodong/cec13- niching/ competition/.(4)c1 , c2 = 2.0, χ = 1.0 but with a low inertia to promote local convergence (ω = 0.1).Table II shows the convergence rates of NMMSO and dADE for ε = 10−1, and these plus N-VMO for ε = 10−4 (convergence results for ε = 10−1 are not reported in [9]). At the ε = 10−1 level dADE performs the best, having the fastest mean convergence 10 times to NMMSO’s nine. At the ε = 10−4 level however NMMSO performs much better than both the other algorithms, having faster convergence at this level on 12 of the problems. On the other eight problems none of the algorithms converged to all the global optima on any runatε=10−4.Tables III and IV give the success rate and peak ratio results across the 20 test problems for all five levels of accuracy for each of the algorithms. NMMSO has the best/equal best SRF6 F7 150328 200000F8 393667 17665 400000F9 F10 400000 12904 0 216935209 0 200000 200000400000 18177240000040000033324 400000400000 95904 0400000
TABLE IVMEAN PEAK RATIOS OF NMMSO, N-VMO AND DADE/NRAND/1/BIN. BEST VALUES FOR EACH PROBLEM AND ACCURACY LEVEL ARE UNDERLINED.￼￼￼F1 F2 F3 F4 F5￼￼ε NMMSO￼￼N-VMOdADE NMMSO￼￼N-VMOdADE NMMSO￼￼N-VMOdADE NMMSO￼￼N-VMOdADE NMMSO￼N-VMO￼￼dADE10−1 1.00010−2 1.00010−3 1.00010−4 1.00010−5 1.000￼￼￼￼￼￼￼￼￼￼￼￼1.000 1.000 1.000 1.000 1.000￼￼￼￼￼￼￼￼￼￼￼￼￼1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000￼￼￼￼￼￼￼￼￼￼￼￼1.000 1.000 1.000 1.000 1.000￼￼￼￼￼￼￼￼￼￼￼￼￼1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000￼￼￼￼￼￼￼￼￼￼￼￼1.000 1.000 1.000 1.000 1.000￼￼￼￼￼￼￼￼￼￼￼￼￼1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000￼￼￼￼￼￼￼￼￼￼￼￼1.000 1.000 1.000 1.000 1.000￼￼￼￼￼￼￼￼￼￼￼￼￼1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000￼￼￼￼￼￼￼￼￼￼￼1.000 1.000 1.000 1.000 1.000￼￼￼￼￼￼￼￼￼￼￼1.000 1.000 1.000 1.000 1.000￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼F6 F7 F8 F9 F10￼￼ε NMMSO￼￼N-VMOdADE NMMSO￼￼N-VMOdADE NMMSO￼￼N-VMOdADE NMMSO￼￼N-VMOdADE NMMSO￼N-VMO￼￼dADE10−1 0.99810−2 0.99810−3 0.99810−4 0.99710−5 0.000￼￼￼￼￼￼￼￼1.000 1.000 0.940 0.670 0.000￼￼￼￼￼￼￼￼￼￼1.000 1.000 1.000 1.000 1.000 1.000 0.984 1.000 0.000 1.000￼￼￼￼￼￼￼￼￼￼1.000 1.000 0.945 0.901 0.806￼￼￼￼￼￼￼￼￼￼1.000 0.984 0.962 0.984 0.892 0.983 0.823 0.981 0.732 0.980￼￼￼￼￼￼￼￼0.412 0.294 0.270 0.198 0.027￼￼￼￼￼￼￼￼0.837 0.930 0.595 0.922 0.545 0.920 0.431 0.917 0.356 0.913￼￼1.0000.683 0.399 0.275 0.192￼￼￼￼￼￼￼￼￼1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000 1.000￼￼￼￼￼￼￼￼￼￼￼1.000 1.000 1.000 1.000 0.968￼￼￼￼￼￼￼￼￼￼0.985 0.978 0.981 0.967 0.947￼￼￼￼￼￼￼￼￼￼￼F11 F12 F13 F14 F15￼￼ε NMMSO￼￼N-VMOdADE NMMSO￼￼N-VMOdADE NMMSO￼￼N-VMOdADE NMMSO￼￼N-VMOdADE NMMSO￼N-VMO￼￼dADE10−1 1.00010−2 1.00010−3 1.00010−4 1.00010−5 1.000￼￼￼￼￼￼￼￼￼￼￼￼1.0000.667 0.667 0.667 0.667￼￼￼￼￼￼￼￼￼0.893 0.998 0.667 0.998 0.667 0.998 0.667 0.998 0.667 0.998￼￼￼￼￼￼￼0.848 0.745 0.725 0.713 0.565￼￼￼￼￼￼￼￼0.998 0.993 0.887 0.993 0.745 0.990 0.740 0.990 0.728 0.990￼￼￼￼￼￼￼1.0000.667 0.667 0.667 0.663￼￼￼￼￼￼￼￼￼0.743 0.770 0.667 0.740 0.667 0.713 0.667 0.710 0.667 0.703￼￼￼￼￼￼1.0000.667 0.667 0.667 0.637￼￼￼￼￼￼￼￼￼0.923 0.673 0.667 0.673 0.655 0.673 0.655 0.670 0.655 0.668￼￼￼￼1.000 0.713 0.668 0.623 0.390￼￼￼￼￼￼￼￼1.0000.620 0.615 0.627 0.620￼￼￼￼￼￼￼￼￼￼￼￼F16 F17 F18 F19 F20￼￼ε NMMSO￼￼N-VMOdADE NMMSO￼￼N-VMOdADE NMMSO￼￼N-VMOdADE NMMSO￼￼N-VMOdADE NMMSO￼N-VMO￼￼dADE10−1 0.66310−2 0.66010−3 0.66010−4 0.66010−5 0.660￼￼￼￼￼￼￼1.000 0.703 0.653 0.653 0.633￼￼￼￼￼￼￼￼￼￼0.873 0.553 0.667 0.548 0.667 0.543 0.667 0.538 0.667 0.538￼￼￼￼￼￼￼￼￼1.0000.475 0.440 0.413 0.320￼￼￼￼￼￼￼￼￼0.938 0.633 0.472 0.633 0.417 0.633 0.403 0.633 0.410 0.633￼￼￼￼￼0.9870.483 0.470 0.470 0.360￼￼￼￼￼￼￼￼￼0.683 0.477 0.660 0.470 0.630 0.463 0.633 0.447 0.627 0.443￼￼￼￼￼￼￼￼￼0.340 0.133 0.133 0.130 0.103￼￼￼￼￼￼￼￼0.420 0.183 0.143 0.180 0.063 0.178 0.018 0.178 0.000 0.178￼￼￼￼￼￼0.000 0.000 0.000 0.000 0.000￼￼￼￼￼￼0.030 0.000 0.002 0.005 0.000￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼value on 57% of the problem/accuracy level combinations. N- VMO achieves this for 44% and dADE 36%.4 For 26% of the problem/accuracy level combinations all of the optimisers have an SR of zero. On the mean PR measure, NMMSO has the best/equal best value on 79% of the problem/accuracy level combinations. N-VMO achieves this for 43% and dADE 41%. No algorithm found any solutions at the ε = 10−5 level on F6. NMMSO tends to have relatively better performance at the higher accuracy levels. This would indicate that once NMMSO has identified a peak, the low inertia swarms are more effective at exploiting it to a high level of accuracy in a rapid fashion compared to the other algorithms.Table V presents the overall performance assessment of NMMSO. The mean PR for the five accuracy levels on each of the 20 test functions are combining into a single average, and compared to the results of the 15 state-of-the-art entrants to the CEC 2013 competition (results from [1]), along with MEA and MSSPSO. NMMSO can be seen to be extremely competitive with the current state-of-the-art, having the highest mean and median PR yet observed.Figure 2 shows the number of swarms maintained by each run of NMMSO for each of the problems. As can be seen, when there are only global modes, the number of swarms maintained converges to the number of global modes (F2, F4, F7, F9 and F10). For problems with very many local optima the number of swarms can be seen to constantly rise, however, due to the search bias toward the better performing mode estimates, this does not prevent good convergence results on these problems. Interestingly, on the composite functions with 10-20D NMMSO can be seen to consistently hone just a few peaks until at some point the number of swarms rises quickly.4There appear to be some data entry issues in the tabulated results for the some of peak ratios in [8], as the values reported increase from ε = 10−3 to 10−4 for F15 and F18, and from ε = 10−2 to 10−4 for F20.TABLE VAVERAGE RESULTS ACROSS ALL TEST PROBLEMS AND ACCURACY LEVELS OF NMMSO, MEA AND MSSPSO, ALONG WITH RESULTS OF MULTI-MODAL ALGORITHMS COMPARED IN THE CEC 2013 COMPETITION (DETAILED IN [1]) ON THE PEAK RATIO.￼￼Algorithm￼Median￼￼Mean￼St. D.￼NMMSO MEA [16] MSSPSO [15]￼￼￼0.99330.2167 0.0000￼￼￼￼￼0.82710.3676 0.2179￼￼￼￼￼￼0.2535 0.3878 0.3901￼￼￼A-NSGA-II [17] CMA-ES [7] CrowdingDE [18] dADE/nrand/1 [8] dADE/nrand/2 [8] DECG [19] DELG [19] DELS-aj [19] DE/nrand/1 [20] DE/nrand/2 [20] IPOP-CMA-ES [21] NEA1 [6] NEA2 [6] N-VMO [9] PNA-NSGA-II [22]￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼0.0740 0.7750 0.6667 0.7488 0.7150 0.6567 0.6667 0.6667 0.6386 0.6667 0.2600 0.6496 0.8513 0.7140 0.6660￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼0.3275 0.7137 0.5731 0.7383 0.6931 0.5516 0.5706 0.5760 0.5809 0.6082 0.3625 0.6117 0.7940 0.6983 0.6141￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼0.4044 0.2807 0.3612 0.3010 0.3174 0.3992 0.3925 0.3857 0.3338 0.3130 0.3117 0.3280 0.2332 0.3307 0.3421￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼￼This is probably due to tendency of NMMSO to merge local modes that live on larger landscape features. Figure 3 shows the growth of a swarm population over time as visualised in X for some of the 2D test problems. Where the global/local peaks/basins are deformations from the plane the number of modes identified quickly increases (see e.g. F6, and regions in F12 and F13), as the mid-points always tend to be lower between any pairing of global/local mode estimate. Where however local modes lie on a larger landscape feature (e.g. the peak mid way down on the right of F11 and F12), these swarms tend not to be sustained, as pairing with a swarm converging on a mode ‘further’ up the larger landscape feature
￼10 10 10 10 10F1 F2 F3 F4 F5# Swarms# Swarms# Swarms# Swarms# Swarms# Swarms# Swarms# Swarms# Swarms# Swarms# Swarms# Swarms# Swarms# Swarms# Swarms# Swarms# Swarms# Swarms# Swarms# Swarms55555000000300 200 1000 1000 Iteration20 F11 15105400400 300 200400200F6F740 600F8200 F9 150100100 Iteration20005050 Iteration1000 20 40 60 80 Iteration0 500 1000 0 Iteration50 100 150 IterationF10100 200 Iteration200 200200020000 1000 2000 3000 IterationF13500 2000 Iteration4000030 20 100 1000 Iteration15010050400105200 00000F12F14600 F15 40020060 40 20200100000000 1000 2000 0 1000 2000 0 2000 4000 0 2000 4000 0 2000 4000Iteration Iteration Iteration Iteration F16 F17 F18 F1940 30 20 10IterationF20100000000 2000 4000 6000 0 2000 4000 0 2 4 0 2 4 0 2 4 6Iteration Iteration Iteration x 104 Iteration x 104 Iteration x 104Fig. 2. Number of swarms maintained by each run on each problem, recorded at each iteration until all global optima have converged to within 10−5, or the function evaluations allowed are exhausted. Swarms recorded at line 11 of Figure 1. Mean of runs plotted in red (when a run has terminated, the size of its final population is used in the calculation of the mean swarm size until all runs complete).will tend to result in a mid-point that is higher than the lower swarm gbest – causing the paired swarms to be merged.VI. DISCUSSIONWe have introduced a new multi-modal optimiser which utilises a number of self-contained but communicating sub- swarms to search for modes in the fitness landscape. The approach builds on a number of properties which have been identified in effective multi-modal optimisers, and continu- ously hones mode estimates by exploiting individual swarms in parallel, rather than searching in local regions and moving on like other multi-swarm approaches to multi-modal optimi- sation. Particles may additionally split off to form new swarms, or migrate between swarms by splitting and subsequently merging. Results on the CEC 2013 niching test problems show that the proposed algorithm is extremely competitive with the current state-of-the-art, and gives robust performance, even though seeded by a single random solution in X. Nevertheless, the number of parameters is still larger than would be generally desirable: future work will be focused on reducing these (via self-adaptation) as well as applying NMMSO to multi-modal engineering design problems. Note however that the optimiser does not require a niching radius or number of niches to be set – as it dynamically fits both of these locally, based upon the distance between the current peak estimate locations being maintained. MATLAB code forthe NMMSO, MEA and MSSPSO algorithms is available at https://github.com/fieldsend.ACKNOWLEDGEMENTThe author would like to thank Prof. Xiaodong Li, Prof. Andries Engelbrecht, and Dr Michael Epitropakis, the organ- isers of the CEC 2013 “Competition on Niching Methods for Multimodal Optimization”, for making the competition test problem code and evaluation functions readily available online for the community.REFERENCES[1] X. Li, A. Engelbrecht, and M. Epitropakis, “Results of the 2013 IEEE CEC Competition on Niching Methods for Multimodal Optimization.” Presented at 2013 IEEE Congress on Evolutionary Computation Com- petition on: Niching Methods for Multimodal Optimization, 2013.[2] J. Holland, Adaptation in Natural and Artificial Systems. University of Michigan Press, 1975.[3] D. E. Goldberg and J. Richardson, “Genetic algorithms with sharing for multimodal function optimisation,” in Proceedings of the Second International Conference on Genetic Algorithms and their Application, 1987, pp. 41–49.[4] B. Sareni and L. Kra ̈henbu ̈hl, “Fitness Sharing and Niching Methods Revisited,” IEEE Transactions on Evolutionary Computation, vol. 2, no. 3, pp. 97–106, 1998.[5] X. Li and K. Deb, “Comparing lbest PSO niching algorithms using different position update rules,” in IEEE Congress on Evolutionary Computation, 2010, pp. 1564–1571.[6] M. Preuss, “Niching the CMA-ES via Nearest-better Clustering,” inProceedings of the 12th Annual Conference Companion on Genetic and Evolutionary Computation, ser. GECCO ’10, 2010, pp. 1711–1718.
￼Function evaluations25 250 2500 25000 25000010 10 10 10 105555500000−5 −5 −5 −5 −5−10 −10 −10 −10 −10−10 −5 0 5 10 −10 −5 0 5 10 −10 −5 0 5 10 −10 −5 0 5 10 −10 −5 0 5 1055555F110 0 0 0 0−5 −5 −5 −5 −5−5 0 5−5 0 5−5 0 5−5 0 5−5 0 555555F120 0 0 0 0−5 −5 −5 −5 −5−5 0 5−5 0 5−5 0 5−5 0 5−5 0 555555F130 0 0 0 0−5 −5 −5 −5 −5−5 0 5−5 0 5−5 0 5−5 0 5−5 0 5Fig. 3. Swarm gbests (marked with a ‘⊗’), and swarm particles (marked with a ‘·’) of NMMSO at different numbers of function evaluations for five of the 2D test problems. Function response coloured from high (dark red) to low (dark blue).F6[7] N. Hansen and A. Ostermeier, “Completely Derandomized Self- Adaptation in Evolution Strategies,” Evolutionary Computation, vol. 9, no. 2, pp. 159–195, 2001.[8] M. G. Epitropakis, X. Li, and E. K. Burke, “A dynamic archive niching differential evolution algorithm for multimodal optimization,” in IEEE Congress on Evolutionary Computation, 2013, pp. 79–86.[9] D. Molina, A. Puris, R. Bello, and F. Herrera, “Variable mesh optimiza- tion for the 2013 CEC Special Session Niching Methods for Multimodal Optimization,” in IEEE Congress on Evolutionary Computation, 2013, pp. 87–94.[10] J. E. Fieldsend, “Multi-Modal Optimisation using a Localised Surrogates Assisted Evolutionary Algorithm,” in UK Workshop on Computational Intelligence (UKCI 2013), 2013, pp. 88–95.[11] ——, “Using an adaptive collection of local evolutionary algorithms for multi-modal problems,” Soft Computing, in press.[12] J. Kennedy and R. Eberhart, “Particle swarm optimization,” in IEEE International Conference on Neural Networks. Perth, Australia: IEEE Service Center, 1995, pp. 1942–1948.[13] J. Fieldsend, “Multi-objective particle swarm optimisation methods,” Department of Computer Science, University of Exeter, Tech. Rep. 419, March 2004.[14] S. Chen, “Locust Swarms - A new multi-optima search technique,” in IEEE Congress on Evolutionary Computation, 2009, pp. 1745–1752.[15] J. Zhang, D.-S. Huang, and K.-H. Liu, “Multi-Sub-Swarm Optimization Algorithm for Multimodal Function Optimization,” in IEEE Congress on Evolutionary Computation, 2007, pp. 3215–3220.[16] R. K. Ursem, “Multinational evolutionary algorithms,” in Proceedings of the Congress on Evolutionary Computation, 1999, pp. 1633–1640.[17] K. Deb and A. Saha, “Multimodal Optimization Using a Bi-objective Evolutionary Algorithm,” Evolutionary Computation, vol. 20, no. 1, pp. 27–62, 2012.[18] R. Thomsen, “Multimodal optimization using crowding-based differen- tial evolution,” in IEEE Congress on Evolutionary Computation, 2004, pp. 1382–1389.[19] J. Ronkkonen, “Continuous Multimodal Global Optimization with Dif- ferential Evolution-Based Methods,” Ph.D. dissertation, Lappeenranta University of Technology, Finland, 2009.[20] M. G. Epitropakis, V. P. Plagianakos, and M. N. Vrahatis, “Finding mul- tiple global optima exploiting differential evolution’s niching capability,” in IEEE Symposium on Differential Evolution (SDE), 2011, pp. 1–8.[21] A. Auger and N. Hansen, “A restart CMA evolution strategy with increasing population size,” in IEEE Congress on Evolutionary Com- putation, vol. 2, 2005, pp. 1769–1776.[22] S. Bandaru and K. Deb, “A parameterless-niching-assisted bi-objective approach to multimodal optimization,” in IEEE Congress on Evolution- ary Computation, 2013, pp. 95–102.[23] X. Li, A. Engelbrecht, and M. G. Epitropakis, “Benchmark Functions for CEC’2013 Special Session and Competition on Niching Methods for Multimodal Function Optimization,” Evolutionary Computation and Machine Learning Group, RMIT University, Tech. Rep., 2013.</Text>
        </Document>
        <Document ID="13">
            <Title>CEC</Title>
            <Text>test</Text>
        </Document>
        <Document ID="18">
            <Title>Discussion</Title>
            <Text>test</Text>
        </Document>
        <Document ID="0">
            <Title>Paper</Title>
        </Document>
        <Document ID="8">
            <Title>The Algorithm</Title>
        </Document>
        <Document ID="14">
            <Title>Structure of the project</Title>
            <Text>test [#fieldsend_2014]</Text>
        </Document>
        <Document ID="20">
            <Title>Introduction</Title>
            <Text>In the recent years R has become the statistical programming language of choice for many people. Since its introduction in 1992. </Text>
        </Document>
        <Document ID="9">
            <Title>The Implementation</Title>
        </Document>
    </Documents>
</SearchIndexes>