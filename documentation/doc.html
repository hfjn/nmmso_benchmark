<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <title></title>
  <style type="text/css">code{white-space: pre;}</style>
  <!--[if lt IE 9]>
    <script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
  <![endif]-->
  <link rel="stylesheet" href="/Users/jhoffjann/.pandoc/marked/kultiad-serif.css">
</head>
<body>



<h1 id="introduction"><span class="header-section-number">1</span> Introduction</h1>
<p>In the recent years R has become the statistical programming language of choice for many scientist. The strength of R of being a domain specific language has also become one of its weaknesses. Since new research findings in statistical computing are split up over several languages like R, Matlab or SciPy<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a> it often becomes difficult to compare new methods with established ones. Since it is also hard to interface those languages due to different architectures, data storage mechanisms there is often no other way than to reimplement new methods in a different programming language to create a common scope.</p>
<p>An example for a well perceived new finding in statistical computing is the NMMSO-Algorithm by Jonathan E. Fieldsend <span class="citation">(Fieldsend 2014)</span>. It won the niching competition in 2015 held by the CEC and is only written in Matlab. Since the chair ‘Information Systems and Statistics’ at the Westfälische Wilhelms-Universität Münster, Germany is mainly concentrating its work on Statistical Computing in R an implementation of this algorithm became interesting.</p>
<p>As part of this Seminar Project in the context of the Seminar ‘Statistical Computing in R’ a reimplementation of the NMMSO algorithm in R (nmmso.R) will be presented. During this technical documentation, the general function of the algorithm and the used test cases by the CEC will be shown. Afterwards the structure and used techniques and libraries, as well as problems and pitfalls due to the different behaviours of R and Matlab, will be shown. The documentation will be closed by the benchmarking results and different test cases.</p>
<p>It was the goal of this project to keep up high comparability with the original code, to ensure the correct functionality and easily implement changes to the original codebase in this program. To reach this, unit tests were used where possible and continouous comparison between part results of the original implementation and nmmso.R where used to ensure functioning. Additionally a benchmarking suite, which builds on the CEC Benchmarking Suite for Niching Algorithm was implemented to evaluate and test the functioning of nmmso.R with the same characteristics as in the original implementation.</p>
<h1 id="general-function"><span class="header-section-number">2</span> General Function</h1>
<p>The starting point of the project was the paper provided by Dr. Jonathen E. Fieldsend <span class="citation">(Fieldsend 2014)</span> on the Niching Migratory Multi-Swarm Optimiser (NMMSO) algorithm. NMMSO is a multi-modal optimiser which relies heavily on multiple swarms which are generated on the landscape of an function in order to find the global optima. It is build around three main pillars: (1) dynamic in the numbers of dimensions, (2) self-adaptive without any special preparation and (3) exploitative local search to quickly find peak estimates <span class="citation">(Fieldsend 2014, p. 1)</span>.</p>
<p>Multi-modal optimisation in general is not that different from well known and widely discussed single-objective optimisation, but in difference to it the goal of the algorithms in the multi-modal is not to find just one single optimising point but all possible points <span class="citation">(Fieldsend 2014, p. 1)</span>. To reach this goal many multi-modal optimization algorithms use strategies oriented on the biological world and utilize swarm intelligence to find optima defined by the search parameters <span class="citation">(Yang 2009)</span>. In order to do so, many early multi-modal optimisation algorithms needed defined parameters <span class="citation">(Fieldsend 2014, p. 1)</span>.</p>
<p>Newer algorithms fall in the field of self-tuning and try to use different mathematical paradigms like nearest-best clustering with covariance matrices <span class="citation">(Preuss 2012)</span> and strategies like storing the so far best found global optima estimators to provide them as parameters for new optimisation runs <span class="citation">(Epitropakis et al. 2013)</span>. Contradictory to that NMMSO goes another way and uses the the swarm strategy in order to find which store their current <span class="citation">(Fieldsend 2014)</span>.</p>
<p>In order to do so NMMSO follow a strict structure which can be seen in the following pseudo-code</p>
<pre><code>nmmso(max_evals, tol, n, max_inc, c_1, c_2, omega)
    S: initialise_swarm(1)
    evaluations := 1
    while evaluations &lt; max_evals:
        while flagged_swarms(S) == true:
            {S, m} := attempt_merge(S, n, tol)
            evals := evals + m
        S := increment(S, n, max_inc, c_1, c_2, omega)
        evals := evals + min(|S|, max_inc)
        {S, k} := attempt_separation(S, tol)
        evals := evals + k
        S := add_new_swarm(S)
        evals := evals + 1
    {X*, Y*} := extract_gbest(S)
    return X*,Y*</code></pre>
<p>This structure wasn’t modified during the reimplementation of NMMSO to keep comparability and the possibility to fix bugs at a high level. The only newly introduced setting was the possibility to modify the c_1, c_2, w as parameters from the outside. In the original version those parameters are part of the program code.</p>
<table>
<thead>
<tr class="header">
<th align="left"></th>
<th align="left">standard value</th>
<th align="left">used value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">evaluations</td>
<td align="left">0</td>
<td align="left">0</td>
</tr>
<tr class="even">
<td align="left">max_evol</td>
<td align="left">100</td>
<td align="left">100</td>
</tr>
<tr class="odd">
<td align="left">tol_val</td>
<td align="left">10^-6</td>
<td align="left">10^-6</td>
</tr>
<tr class="even">
<td align="left">c_1</td>
<td align="left">2.0</td>
<td align="left">2.0</td>
</tr>
<tr class="odd">
<td align="left">c_2</td>
<td align="left">2.0</td>
<td align="left">2.0</td>
</tr>
<tr class="even">
<td align="left">omega</td>
<td align="left">0.1</td>
<td align="left">0.1</td>
</tr>
</tbody>
</table>
<hr />
<h1 id="cec-algorithms"><span class="header-section-number">3</span> CEC Algorithms</h1>
<h2 id="cec"><span class="header-section-number">3.1</span> CEC</h2>
<p>The IEEE Congress of Evolutionary Computation (CEC) is one of the largest, most important and recognised conferences within Evolutionary Computation (EC). It is organised by the IEEE Computational Intelligence Society in cooperation with the Evolutionary Programming Society, and covers most of the subtopics of the EC.</p>
<p>In order to validate the potential of the NMMSO algorithm, it was submitted to the IEEE CEC 2013 held in Cancun, Mexico. Here, Dr. Fieldsend was provided with some multimodal benchmark test functions with different dimension sizes and characteristics, for evaluating niching algorithms developed by Dr. Xiaodong Li, Dr. Andries Engelbrecht and Dr. Michael G. Epitropakis <span class="citation">(Epitropakis et al. 2013)</span>. They state that even if several niching methods have been around for many years, further advances in this area have been hindered by several obstacles; most of the studies focus on very low dimensional multimodal problems (2 or 3 dimensions) making this more complicated to asses theses methods’ scalability to high dimensions with better performance. The benchmark tool includes 20 test functions (in some cases the same function but with different dimension sizes), which includes 10 simple, well-known and widely used benchmark functions, based on recent studies, and more complex functions following the paradigm of composition functions. In the following section, they will be briefly explained:</p>
<pre><code>•   F1: Five-Uneven-Peak Trap (1D)
•   F2: Equal Maxima (1D)
•   F3: Uneven Decreasing Maxima (1D)
•   F4: Himmelblau (2D)
•   F5: Six-Hump Camel Back (2D)
•   F6: Shubert (2D, 3D)
•   F7: Vincent (2D, 3D)
•   F8: Modified Rastrigin - All Global Optima (2D)
•   F9: Composition Function 1 (2D)
•   F10: Composition Function 2 (2D)
•   F11: Composition Function 3 (2D, 3D, 5D, 10D)
•   F12: Composition Function 4 (3D, 5D, 10D, 20D)</code></pre>
<p>All of the test functions are formulated as maximisation problems. F1, F2 and F3 are simple 1D multimodal functions, while F4 and F5 are simple 2D functions and not scalable. F6 to F8 are scalable multimodal functions. The number of global optima for F6 and F7 are determined by the dimension. However, for F8, the number of global optima is independent from the dimension, therefore it can be controlled by the user. F9 to F12 are scalable multimodal functions constructed by several basic functions with different properties (Sphere function, Grienwank, Rastrigin, Weierstrass and the Expanded Griewank’s plus Rosenbrock’s function). F9 and F10 are separable, and non-symmetric, while F11 and F12 are non-separable, non-symmetric complex multimodal functions. The number of global optima in all of the composition functions is independent from the number of dimensions, therefore can be controlled by the user <span class="citation">(Epitropakis et al. 2013)</span>.</p>
<p><strong>Maybe write each math equation or the R code</strong></p>
<p>https://en.wikipedia.org/wiki/IEEE_Congress_on_Evolutionary_Computation</p>
<h2 id="implementation-and-pitfalls"><span class="header-section-number">3.2</span> Implementation and Pitfalls</h2>
<p><strong>write also about the count_goptima and so on</strong></p>
<hr />
<h1 id="the-implementation"><span class="header-section-number">4</span> The Implementation</h1>
<h2 id="structure-of-the-project"><span class="header-section-number">4.1</span> Structure of the project</h2>
<p>After analysing the algorithm provided in Matlab by Dr. Fieldsend, it was decided to first translate each of the functions into the R programming language. At first instance, this task seemed to be simple because most of the functions were basically managing matrices and vectors, but later this became a problem that will be addressed in the pitfalls’ section of this paper.</p>
<p>Once all the NMMSO functions existed in R and having the input data, the testing phase started. It has be said, that one of the biggest problems when you code an already existing program into another programming language, is the different behaviours corresponding to each object (in case of an object-oriented language) or its main structure. The first runs came with several errors regarding the matrix generation and handling, slowing down the project in a near future. Using GitHub, it was easier to attack these problems in parallel, having one developer reviewing different functions and the other one, fixing other bugs and continue the testing phase. Also, this was achieved in an easier way, thanks that each function was coded in an independent R file, making easier and faster the debugging and the fixing of each problem.</p>
<p>During the developing time, an issue raised with the CEC benchmark tool. In order to compare the R implementation of the NMMSO algorithm with the original one, it was mandatory to use this tool to test each of its functions with the new algorithm and compare results. After several complications with the original test suite (these complications will be addressed in the pitfalls’ section), it was decided to recode each of the functions as an independent R package to avoid any further complication and having an easier and more trustworthy comparison of the NMMSO algorithm in R.</p>
<h2 id="pitfalls-and-problems"><span class="header-section-number">4.2</span> Pitfalls and Problems</h2>
<p>test</p>
<h1 id="benchmark-and-comparison"><span class="header-section-number">5</span> Benchmark and Comparison</h1>
<p>To compare nmmso.R with the original NMMSO the CEC test cases were used to run the same benchmarks as in the original submission <span class="citation">(Fieldsend 2014)</span>. There 4 different Ratios were used to measure the performance of certain algorithms. Three of those measures (Peak Ratio, Success Ratio and Convergence Speed) have been introduced in <span class="citation">(Epitropakis et al. 2013, pp. 6–7)</span> to create a common point of comparison. The fourth ratio is special for the nmmso algorithm since it tracks the number of swarms over the iterations of the algorithm. Nmmso.R uses the same measures to reach the highest comparability possible.</p>
<p>The first measure used is the Success Ratio (SR). The Success Ratio is defined as the percentage of Successful runs (runs that found all global optima) over all runs <span class="citation">(Li et al. 2013, p. 7)</span>. As for the other ratios this measure was taken over several independent runs and collectively evaluated. The taken measures for the Success Ratio can be found in Table 2. <br /><span class="math display">$$\frac{successful\ runs}{NR} = SR $$</span><br /> Here <span class="math inline"><em>N</em><em>R</em></span> denotes the Number of runs done to reach this measure. </p>
<table style="width:78%;">
<caption>Success Ratio over given runs (Measure of share of runs which found all global optima)</caption>
<colgroup>
<col width="13%" />
<col width="8%" />
<col width="9%" />
<col width="11%" />
<col width="12%" />
<col width="13%" />
<col width="8%" />
</colgroup>
<thead>
<tr class="header">
<th align="center"> </th>
<th align="right">0.1</th>
<th align="right">0.01</th>
<th align="right">0.001</th>
<th align="right">0.0001</th>
<th align="right">0.00001</th>
<th align="right">runs</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><strong>F1</strong></td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">37</td>
</tr>
<tr class="even">
<td align="center"><strong>F2</strong></td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">35</td>
</tr>
<tr class="odd">
<td align="center"><strong>F3</strong></td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">37</td>
</tr>
<tr class="even">
<td align="center"><strong>F4</strong></td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">37</td>
</tr>
<tr class="odd">
<td align="center"><strong>F5</strong></td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">34</td>
</tr>
<tr class="even">
<td align="center"><strong>F6</strong></td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">34</td>
</tr>
<tr class="odd">
<td align="center"><strong>F7</strong></td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">34</td>
</tr>
<tr class="even">
<td align="center"><strong>F8</strong></td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">0.94</td>
<td align="right">0.71</td>
<td align="right">17</td>
</tr>
<tr class="odd">
<td align="center"><strong>F9</strong></td>
<td align="right">0.95</td>
<td align="right">0.95</td>
<td align="right">0.95</td>
<td align="right">0.95</td>
<td align="right">0.95</td>
<td align="right">20</td>
</tr>
<tr class="even">
<td align="center"><strong>F10</strong></td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">34</td>
</tr>
<tr class="odd">
<td align="center"><strong>F11</strong></td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">33</td>
</tr>
<tr class="even">
<td align="center"><strong>F12</strong></td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">34</td>
</tr>
<tr class="odd">
<td align="center"><strong>F13</strong></td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">34</td>
</tr>
<tr class="even">
<td align="center"><strong>F14</strong></td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">33</td>
</tr>
<tr class="odd">
<td align="center"><strong>F15</strong></td>
<td align="right">0.96</td>
<td align="right">0.96</td>
<td align="right">0.96</td>
<td align="right">0.96</td>
<td align="right">0.96</td>
<td align="right">26</td>
</tr>
<tr class="even">
<td align="center"><strong>F16</strong></td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">13</td>
</tr>
<tr class="odd">
<td align="center"><strong>F17</strong></td>
<td align="right">0.17</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">12</td>
</tr>
<tr class="even">
<td align="center"><strong>F18</strong></td>
<td align="right">0.38</td>
<td align="right">0.38</td>
<td align="right">0.38</td>
<td align="right">0.31</td>
<td align="right">0.31</td>
<td align="right">16</td>
</tr>
<tr class="odd">
<td align="center"><strong>F19</strong></td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">13</td>
</tr>
<tr class="even">
<td align="center"><strong>F20</strong></td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">12</td>
</tr>
</tbody>
</table>
<p>The second measure introduced by the CEC committee and also used by Dr. Fieldsend is the Convergence Rate. The Convergence Rate (CR) measures the needed evaluations per Accuracy and Function to find all global optima <span class="citation">(Li et al. 2013, p. 7)</span>. This measure takes the mean of evaluations over all runs. The results of this measure can be found in Table 3.</p>
<p><br /><span class="math display">$$\frac{\sum\nolimits_{n=1}^{NR} evals_{n}}{NR} = CR$$</span><br /> In this measure <span class="math inline"><em>e</em><em>v</em><em>a</em><em>l</em><em>s</em></span> denotes the number of evaluations done. </p>
<table style="width:79%;">
<caption>Convergence Rates over given runs (Mean of evaluations needed to find all global optima, if all optima have never been found the maximum allowed evaluations for that function were taken.)</caption>
<colgroup>
<col width="13%" />
<col width="9%" />
<col width="9%" />
<col width="11%" />
<col width="12%" />
<col width="13%" />
<col width="8%" />
</colgroup>
<thead>
<tr class="header">
<th align="center"> </th>
<th align="right">0.1</th>
<th align="right">0.01</th>
<th align="right">0.001</th>
<th align="right">0.0001</th>
<th align="right">0.00001</th>
<th align="right">runs</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><strong>F1</strong></td>
<td align="right">622</td>
<td align="right">815</td>
<td align="right">1018</td>
<td align="right">1205</td>
<td align="right">1441</td>
<td align="right">37</td>
</tr>
<tr class="even">
<td align="center"><strong>F2</strong></td>
<td align="right">179</td>
<td align="right">269</td>
<td align="right">397</td>
<td align="right">533</td>
<td align="right">640</td>
<td align="right">35</td>
</tr>
<tr class="odd">
<td align="center"><strong>F3</strong></td>
<td align="right">35</td>
<td align="right">170</td>
<td align="right">273</td>
<td align="right">390</td>
<td align="right">513</td>
<td align="right">37</td>
</tr>
<tr class="even">
<td align="center"><strong>F4</strong></td>
<td align="right">506</td>
<td align="right">735</td>
<td align="right">961</td>
<td align="right">1201</td>
<td align="right">1455</td>
<td align="right">37</td>
</tr>
<tr class="odd">
<td align="center"><strong>F5</strong></td>
<td align="right">82</td>
<td align="right">194</td>
<td align="right">321</td>
<td align="right">522</td>
<td align="right">788</td>
<td align="right">34</td>
</tr>
<tr class="even">
<td align="center"><strong>F6</strong></td>
<td align="right">19519</td>
<td align="right">24388</td>
<td align="right">30499</td>
<td align="right">42404</td>
<td align="right">200001</td>
<td align="right">34</td>
</tr>
<tr class="odd">
<td align="center"><strong>F7</strong></td>
<td align="right">8564</td>
<td align="right">9211</td>
<td align="right">10604</td>
<td align="right">12328</td>
<td align="right">14646</td>
<td align="right">34</td>
</tr>
<tr class="even">
<td align="center"><strong>F8</strong></td>
<td align="right">194031</td>
<td align="right">231763</td>
<td align="right">271058</td>
<td align="right">320284</td>
<td align="right">354533</td>
<td align="right">17</td>
</tr>
<tr class="odd">
<td align="center"><strong>F9</strong></td>
<td align="right">185670</td>
<td align="right">189360</td>
<td align="right">204110</td>
<td align="right">219559</td>
<td align="right">228586</td>
<td align="right">20</td>
</tr>
<tr class="even">
<td align="center"><strong>F10</strong></td>
<td align="right">887</td>
<td align="right">1326</td>
<td align="right">1728</td>
<td align="right">2254</td>
<td align="right">2758</td>
<td align="right">34</td>
</tr>
<tr class="odd">
<td align="center"><strong>F11</strong></td>
<td align="right">3692</td>
<td align="right">5747</td>
<td align="right">7347</td>
<td align="right">8549</td>
<td align="right">9164</td>
<td align="right">33</td>
</tr>
<tr class="even">
<td align="center"><strong>F12</strong></td>
<td align="right">17321</td>
<td align="right">25823</td>
<td align="right">38464</td>
<td align="right">44660</td>
<td align="right">51792</td>
<td align="right">34</td>
</tr>
<tr class="odd">
<td align="center"><strong>F13</strong></td>
<td align="right">11338</td>
<td align="right">15676</td>
<td align="right">19107</td>
<td align="right">23152</td>
<td align="right">26802</td>
<td align="right">34</td>
</tr>
<tr class="even">
<td align="center"><strong>F14</strong></td>
<td align="right">28776</td>
<td align="right">34298</td>
<td align="right">48738</td>
<td align="right">59775</td>
<td align="right">68576</td>
<td align="right">33</td>
</tr>
<tr class="odd">
<td align="center"><strong>F15</strong></td>
<td align="right">107225</td>
<td align="right">129151</td>
<td align="right">149266</td>
<td align="right">172770</td>
<td align="right">189144</td>
<td align="right">26</td>
</tr>
<tr class="even">
<td align="center"><strong>F16</strong></td>
<td align="right">400001</td>
<td align="right">400001</td>
<td align="right">400001</td>
<td align="right">400001</td>
<td align="right">400001</td>
<td align="right">13</td>
</tr>
<tr class="odd">
<td align="center"><strong>F17</strong></td>
<td align="right">377470</td>
<td align="right">400001</td>
<td align="right">400001</td>
<td align="right">400001</td>
<td align="right">400001</td>
<td align="right">12</td>
</tr>
<tr class="even">
<td align="center"><strong>F18</strong></td>
<td align="right">299577</td>
<td align="right">302391</td>
<td align="right">304385</td>
<td align="right">309050</td>
<td align="right">309450</td>
<td align="right">16</td>
</tr>
<tr class="odd">
<td align="center"><strong>F19</strong></td>
<td align="right">400001</td>
<td align="right">400001</td>
<td align="right">400001</td>
<td align="right">400001</td>
<td align="right">400001</td>
<td align="right">13</td>
</tr>
<tr class="even">
<td align="center"><strong>F20</strong></td>
<td align="right">400001</td>
<td align="right">400001</td>
<td align="right">400001</td>
<td align="right">400001</td>
<td align="right">400001</td>
<td align="right">12</td>
</tr>
</tbody>
</table>
<p>The third measure is the Peak Ratio (PR). It measures the share of found global optima over all runs <span class="citation">(Li et al. 2013, p. 7)</span>. The results of this evaluation can be found in Table 4.</p>
<p><br /><span class="math display">$$\frac{\sum\nolimits_{n=1}^{NR} NOF_{n}}{NKO * NR} = PR$$</span><br /> In this measure <span class="math inline"><em>N</em><em>O</em><em>F</em></span> denotes the number of found optima per run and <span class="math inline"><em>N</em><em>K</em><em>O</em></span> the number of known optima for the function. </p>
<table style="width:78%;">
<caption>Peak Ratio over given runs (Share of found global optima over all runs)</caption>
<colgroup>
<col width="13%" />
<col width="8%" />
<col width="9%" />
<col width="11%" />
<col width="12%" />
<col width="13%" />
<col width="8%" />
</colgroup>
<thead>
<tr class="header">
<th align="center"> </th>
<th align="right">0.1</th>
<th align="right">0.01</th>
<th align="right">0.001</th>
<th align="right">0.0001</th>
<th align="right">0.00001</th>
<th align="right">runs</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><strong>F1</strong></td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">37</td>
</tr>
<tr class="even">
<td align="center"><strong>F2</strong></td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">35</td>
</tr>
<tr class="odd">
<td align="center"><strong>F3</strong></td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">37</td>
</tr>
<tr class="even">
<td align="center"><strong>F4</strong></td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">37</td>
</tr>
<tr class="odd">
<td align="center"><strong>F5</strong></td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">34</td>
</tr>
<tr class="even">
<td align="center"><strong>F6</strong></td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">0</td>
<td align="right">34</td>
</tr>
<tr class="odd">
<td align="center"><strong>F7</strong></td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">34</td>
</tr>
<tr class="even">
<td align="center"><strong>F8</strong></td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">0.98</td>
<td align="right">17</td>
</tr>
<tr class="odd">
<td align="center"><strong>F9</strong></td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">20</td>
</tr>
<tr class="even">
<td align="center"><strong>F10</strong></td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">34</td>
</tr>
<tr class="odd">
<td align="center"><strong>F11</strong></td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">33</td>
</tr>
<tr class="even">
<td align="center"><strong>F12</strong></td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">34</td>
</tr>
<tr class="odd">
<td align="center"><strong>F13</strong></td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">34</td>
</tr>
<tr class="even">
<td align="center"><strong>F14</strong></td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">33</td>
</tr>
<tr class="odd">
<td align="center"><strong>F15</strong></td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">26</td>
</tr>
<tr class="even">
<td align="center"><strong>F16</strong></td>
<td align="right">0.01</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="right">13</td>
</tr>
<tr class="odd">
<td align="center"><strong>F17</strong></td>
<td align="right">0.77</td>
<td align="right">0.74</td>
<td align="right">0.72</td>
<td align="right">0.71</td>
<td align="right">0.67</td>
<td align="right">12</td>
</tr>
<tr class="even">
<td align="center"><strong>F18</strong></td>
<td align="right">0.83</td>
<td align="right">0.83</td>
<td align="right">0.83</td>
<td align="right">0.8</td>
<td align="right">0.8</td>
<td align="right">16</td>
</tr>
<tr class="odd">
<td align="center"><strong>F19</strong></td>
<td align="right">0.44</td>
<td align="right">0.44</td>
<td align="right">0.42</td>
<td align="right">0.42</td>
<td align="right">0.4</td>
<td align="right">13</td>
</tr>
<tr class="even">
<td align="center"><strong>F20</strong></td>
<td align="right">0.15</td>
<td align="right">0.14</td>
<td align="right">0.14</td>
<td align="right">0.14</td>
<td align="right">0.12</td>
<td align="right">12</td>
</tr>
</tbody>
</table>
<p>As a fourth measure, which wasn’t introduced by the CEC committee, but used in the original nmmso implementation <span class="citation">(Fieldsend 2014)</span> the Number of Swarms was chosen. Since this is a continuous measure and therefore no calculation is needed this measure is pictured as graphs. The graphs can be found in Figure 1. The show the development of <span class="math inline"><em>n</em><em>u</em><em>m</em><em>b</em><em>e</em><em>r</em><em>o</em><em>f</em><em>s</em><em>w</em><em>a</em><em>r</em><em>m</em><em>s</em></span> kept by nmmso.R over all iterations. Important to notice here is that <span class="math inline"><em>i</em><em>t</em><em>e</em><em>r</em><em>a</em><em>t</em><em>i</em><em>o</em><em>n</em><em>s</em></span> is different from the <span class="math inline"><em>e</em><em>v</em><em>a</em><em>l</em><em>u</em><em>a</em><em>t</em><em>i</em><em>o</em><em>n</em><em>s</em></span> referenced in the other measures. Iterations are calls to start single runs of nmmso.R and is therefore different from the evaluations taken within the program.</p>
<p>Additionally a fifth measure was introduced which denotes the runtime of nmmso.R for the single functions. These times were taken on the ZIVHPC a scientific High Perfomance Computing Cluster by Westfälische Wilhelms-Universität Münster. Since the nmmso.R is a strictly sequential algorithm the runtimes for single runs will comparable on common computers. The ZIVHPC was only used to parallelize the single runs.</p>
<div class="figure">
<embed src="figure/trend%20curve%20of%20kept%20swarms%20over%20all%2020%20functions.%20The%20red%20curves%20show%20the%20number%20of%20swarms%20kept%20for%20each%20single%20run.%20The%20black%20line%20shows%20the%20mean%20of%20kept%20swarms%20over%20these%20runs.-1.pdf" />
<p class="caption">plot of chunk trend curve of kept swarms over all 20 functions. The red curves show the number of swarms kept for each single run. The black line shows the mean of kept swarms over these runs.</p>
</div>
<p>When comparing those measures with the ones given in the original paper <span class="citation">(Fieldsend 2014)</span> it can be seen that the reimplementation nmmso.R is an overall good resemblance of the original algorithm. The three CEC measures are close to the original taken measures and the trend curves for the number of kept swarms have similar trends.</p>
<p>The biggest differences between the benchmarking results of the two implementations can be seen in the general results of function 14, 15, 16 and 18, as well as in the number of created swarms for the n-dimensional functions:</p>
<ol style="list-style-type: decimal">
<li><p>Function 14 and 15 have a <span class="math inline"><em>S</em><em>u</em><em>c</em><em>c</em><em>e</em><em>s</em><em>s</em> <em>R</em><em>a</em><em>t</em><em>i</em><em>o</em></span> of <span class="math inline">1</span> aswell as as <span class="math inline"><em>P</em><em>e</em><em>a</em><em>k</em></span> <span class="math inline"><em>R</em><em>a</em><em>t</em><em>i</em><em>o</em></span> of one <span class="math inline">1</span> for all accuracy levels. Additionally nmmso.R sometimes found all global optima for Function 18. In contradiction to that the evaluation of all thre function almost never result in the finding of global optima in the evaluation of the original implementation. Only at the lowest accuracy the original implementation is able to find all global optima for Function 14 <span class="citation">(Fieldsend 2014, p. 16)</span>. It is hard to say if this difference is equal to an error in the implementation of nmmso.R or if an error in the original implementation was fixed. Also this could be a difference in the reimplementation of the CEC Benchmarking Tool. Nevertheless, this is interesting point of discussion and worth evaluating.</p></li>
<li><p>nmmso.R performs noticeable worse for Function 16 than the original function. While nmmso.R has a <span class="math inline"><em>P</em><em>e</em><em>a</em><em>k</em></span> <span class="math inline"><em>R</em><em>a</em><em>t</em><em>i</em><em>o</em></span> of <span class="math inline">0.01</span> for an accuracy of <span class="math inline">0.1</span> and <span class="math inline">0</span> for all others, the original implementation reaches a <span class="math inline"><em>P</em><em>e</em><em>a</em><em>k</em></span> <span class="math inline"><em>R</em><em>a</em><em>t</em><em>i</em><em>o</em></span> of around <span class="math inline">0.6</span> for all accuracies. This might be to an implementation error in the CEC Benchmarking Tool. Since it is so significantly worse that it is unlikely that this difference would only occur in one test function.</p></li>
<li><p>Almost all algorithm runs on high-dimensional functions (F12-F20) result in a high number of swarms, while all other results regarding this functions are comparable to the original results. This difference becomes very clear in the case of Functions 17-20. In the paper addressing the original paper the x-axis rank from 0-40,000 iterations, while for the reimplementation limit of 4,000 for Function 17, of 20,000 for Function 18, 6,000 for Function 19 and of 30,000 for Function 20 is enough to show all data sets. This is connected to the creation of much more swarms, which leads to an earlier depletion of the maximum allowed number of evaluations.</p></li>
</ol>
<h1 id="conclusion"><span class="header-section-number">6</span> Conclusion</h1>
<p>test</p>
<h1 id="acknowledgements"><span class="header-section-number">7</span> Acknowledgements</h1>
<p>We want to thank Dr. Jonathan Fieldsend for his continuous help via mail during this seminar. Also the committee of the CEC was always available for questions and concerns during our work. Furthermore a special thanks goes to all employees of the chair for ‘Information Systems and Statistics’ including Dr. Mike Preuß, Jakob Bossek and Pascal Kerschke who were available for any questions regarding the implementation and this report at all times. </p>
<div id="refs" class="references">
<div id="ref-epitropakis_2013">
<p>Epitropakis, M. G., Li, X., and Burke, E. K. 2013. “A dynamic archive niching differential evolution algorithm for multimodal optimization,” in <em>Evolutionary computation (cEC), 2013 iEEE congress on</em>, IEEE, pp. 79–86.</p>
</div>
<div id="ref-fieldsend_2014">
<p>Fieldsend, J. E. 2014. “Running up those hills: Multi-modal search with the niching migratory multi-swarm optimiser,” in <em>Evolutionary computation (cEC), 2014 iEEE congress on</em>, IEEE, pp. 2593–2600.</p>
</div>
<div id="ref-li_2013">
<p>Li, X., Engelbrecht, A., and Epitropakis, M. G. 2013. “Benchmark functions for cEC’2013 special session and competition on niching methods for multimodal function optimization,” <em>RMIT University, Evolutionary Computation and Machine Learning Group, Australia, Tech. Rep</em>.</p>
</div>
<div id="ref-preuss_2012">
<p>Preuss, M. 2012. “Improved topological niching for real-valued global optimization,” in <em>Applications of evolutionary computation</em>, Springer, pp. 386–395.</p>
</div>
<div id="ref-yang_2009">
<p>Yang, X.-S. 2009. “Firefly algorithms for multimodal optimization,” in <em>Stochastic algorithms: Foundations and applications</em>, Springer, pp. 169–178.</p>
</div>
</div>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>SciPy is a common library for the Python Programming language which brings Statistical Computing capabilities to the language. <a href="#fnref1">↩</a></p></li>
</ol>
</div>
</body>
</html>
